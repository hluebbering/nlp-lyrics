[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NLP Song Lyrics",
    "section": "",
    "text": "Overview\nObjective. The following project involves extracting and analyzing Spotify data from top playlists using the Spotify and Genius Lyrics Web API. Natural Language Processing techniques are used to process lyrics and perform sentiment analysis. K-means clustering and PCA analysis are employed to categorize songs and analyze relationships between musical features.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#extracting-spotify-data",
    "href": "index.html#extracting-spotify-data",
    "title": "NLP Song Lyrics",
    "section": "Extracting Spotify Data",
    "text": "Extracting Spotify Data\nGetting started, we want to extract data for a set of tracks within one of Spotify’s top-featured playlists. Leveraging the Spotify Web API, we can seamlessly obtain detailed data for a song, such as the artist, the album it belongs to, its release date, popularity, and audio features like danceability, energy, and tempo.\n\nAccessing the Spotify Web API\nPython libraries like spotipy offer a user-friendly way to interact with the Spotify API, offering a range of functions that streamline tasks like API authentication. To authenticate access, we provide a client ID and secret. Once authenticated, we can interact with the API and retrieve data.\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\nmy_auth = SpotifyClientCredentials(client_id = \"xxx\", client_secret = \"xxx\")\nsp = spotipy.Spotify(auth_manager=my_auth)  # Spotify authentication\n\n\nSpotify’s Featured Playlists\nLet’s take a look at the popular Spotify playlists. Below, the code retrieves a range of Spotify playlists and generates a dataframe containing details for each playlist.\n\n\n\n\n\n\n\nthumbnail\nplaylist_name\nplaylist_id\ndescription\ntotal\n\n\n\n\n0\n\nToday’s Top Hits\n37i9dQZF1DXcBWIGoYBM5M\nShaboozey is on top of the Hottest 50!\n50\n\n\n1\n\nRapCaviar\n37i9dQZF1DX0XUsuxWHRQd\nNew music from Don Toliver, Moneybagg Yo and Central Cee.\n50\n\n\n2\n\nHot Country\n37i9dQZF1DX1lVhptIYRda\nThank you to everyone who helped us heat up Spotify House at CMA Fest! Cover: Shaboozey\n50\n\n\n\n\n\n\n\n\n\n\nExtracting Track Data From Playlist\nNext, we utilize Spotify’s API to extract further details about each song within the playlist. We obtain metadata such as the track name, the artist it’s sung by, the album it belongs to, the release date, and track features such as danceability, tempo, and popularity.\n\ndef get_playlist_tracks(playlist_URI):\n    results = sp.playlist_tracks(playlist_URI)\n    tracks = results[\"items\"]\n    while results[\"next\"]:\n        results = sp.next(results)\n        tracks.extend(results[\"items\"])\n    return tracks\n\nChoose a specific playlist to analyze by copying the URL from the Spotify Player interface. Using that link, the playlist_tracks method retrieves a list of IDs and corresponding artists for each track from the playlist. Specifically, we analyze Spotify’s Today’s Top Hits playlist.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#natural-language-processing",
    "href": "index.html#natural-language-processing",
    "title": "NLP Song Lyrics",
    "section": "Natural Language Processing",
    "text": "Natural Language Processing\nUsing the data gathered from the Spotify API, we now want to extract and process lyrics for each song. This is accomplished through scraping textual lyrical data from the Genius Lyrics website. Following extraction, the lyrics are cleaned before undergoing sentiment analysis.\n\nScraping Song Lyrics\nThe lyricsgenius is a fundamental library allowing for web scraping of the Genius Lyrics website. Through the initialization of the genius variable, one can access the Genius API and retrieve the lyrics of any given song, such as “Too Many Nights” by Metro Boomin.\n\nimport lyricsgenius\ngenius = lyricsgenius.Genius(access_token) # Initialize Genius API\nsong = genius.search_song(\"Too Many Nights\", \"Metro Boomin\")\n\nSearching for \"Too Many Nights\" by Metro Boomin...\nDone.\n\n\n\n\nPre-Processing Text Data\nUsing the genius library, we define a function to fetch the lyrics of a song given the name and artist. Once retrieved, the next step is to pre-process the lyrics. This involves a cleaning process to eliminate patterns that may hinder the overall readability. The script contains the following steps:\n\n\nFetching Track Lyrics\nExpanding Contractions\nConverting Text to Lowercase\nSpell Checking + Censoring\nRemoving Punctuations\nTokenizing and encoding to ASCII\n\n\n\n\ndef clean_song_lyrics(song_name, artist_name):\n    # Fetch song lyrics and clean\n    lyrics = get_song_lyrics(song_name, artist_name) \n    lyrics = profanity.censor(contractions.fix(lyrics).lower(), censor_char=\"\")\n    lyrics = remove_punctuation(lyrics) \n    \n    # Tokenizing and encoding to ASCII\n    return [word.encode(\"ascii\", \"ignore\").decode() for word in word_tokenize(lyrics)]\n\n\nFurther Text Cleaning\nWe employ the Natural Language Toolkit (NLTK) to filter out stopwords and perform lemmatization. Removing common words like “the” condenses the text, allowing for a more thorough analysis of the lyrics’ core message. Lemmatization helps standardize text by transforming different verb variations into their most basic form.\n\n\n\n\n\n\n\n\n\n\nname\nartist\nlyrics\nstopwords_removed\nlemmatized\n\n\n\n\n0\nEspresso\nSabrina Carpenter\n['now', 'he', 'is', 'thinking', 'about', 'me', 'eve...\n['thinking', 'every', 'night', 'sweet', 'guess', 's...\n['think', 'every', 'night', 'sweet', 'guess', 'say'...\n\n\n1\nBIRDS OF A FEATHER\nBillie Eilish\n['i', 'want', 'you', 'to', 'stay', 'i', 'want', 'yo...\n['want', 'stay', 'want', 'stay', 'til', 'grave', 't...\n['want', 'stay', 'want', 'stay', 'til', 'grave', 't...\n\n\n2\nI Had Some Help (Feat. Morgan Wallen)\nPost Malone\n['you', 'got', 'a', 'got', 'ta', 'nerve', 'do', 'no...\n['got', 'got', 'ta', 'nerve', 'baby', 'hit', 'curb'...\n['get', 'get', 'ta', 'nerve', 'baby', 'hit', 'curb'...\n\n\n\n\n\n\n\n\n\n\nTerm Frequency Analysis\n\nLet’s examine the most frequent words. Plotting the frequency distribution helps to determine the occurrence of the most common terms in our lyrical corpus.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#sentiment-analysis",
    "href": "index.html#sentiment-analysis",
    "title": "NLP Song Lyrics",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nThe next process involves implementing pipelines to predict emotions and sentiment in textual content using transformer models designed for text classification and sentiment analysis. Three distinct pipelines are created, each equipped with different models.\n\nfrom transformers import pipeline\n\nclassifiers = [ # Initialize sentiment classifiers\n    pipeline(model='bhadresh-savani/distilbert-base-uncased-emotion'),\n    pipeline(model='cardiffnlp/twitter-roberta-base-sentiment')\n]\n\nOne of the classifiers is the distilbert-base-uncased-emotion model, which detects emotions in texts like sadness, joy, love, anger, fear, and surprise. Another classifier is the roBERTa-base model “trained on 58 million tweets and fine-tuned for sentiment analysis using the TweetEval benchmark” (EMNLP 2020).\nWe then implement the get_lyric_sentiment function, which uses three classifiers to calculate sentiment scores from pre-processed lyrics.\n\n# Function to perform sentiment analysis\ndef get_lyric_sentiment(lyrics, classifiers):\n    text = \" \".join(lyrics)\n    scores = {}\n    for classifier in classifiers:\n        try:\n            predictions = classifier(text, truncation=True)\n            for prediction in predictions[0]:\n                scores[prediction[\"label\"]] = prediction[\"score\"]\n        except Exception as e:\n            print(f\"Error during sentiment analysis: {e}\")\n    return scores\n\nBelow is a graphical representation of the results obtained from the roBERTa-base model. According to the TweetEval reference paper and official Github repository, the resulting labels 0, 1, and 2 correspond to Negative, Neutral, and Positive, respectively.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#putting-it-all-together",
    "href": "index.html#putting-it-all-together",
    "title": "NLP Song Lyrics",
    "section": "Putting it All Together",
    "text": "Putting it All Together\nTo summarize, the code efficiently collects data and performs text analysis on every song in a playlist. Specifically, it systematically processes a list of tracks and corresponding artists while simultaneously conducting a thorough cleaning procedure on the lyrics. Additionally, the program computes a sentiment score for each song based on the lyrics, indicating whether the lyrics are positive, negative, or neutral.\n\n\n\n\n\n\n\n\n\n\nname\nalbum\nartist\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\nacousticness\ndanceability\n...\njoy\nlove\nanger\nfear\nsurprise\nLABEL_0\nLABEL_1\nLABEL_2\nNEGATIVE\nPOSITIVE\n\n\n\n\n0\nEspresso\nEspresso\nSabrina Carpenter\n2024-04-12\n175459\n95\n87\n['pop']\n0.10700\n0.701\n...\n0.698773\n0.159517\n0.038075\n0.046130\n0.005205\n0.058558\n0.745153\n0.196289\n0.988320\n0.011680\n\n\n1\nBIRDS OF A FEATHER\nHIT ME HARD AND SOFT\nBillie Eilish\n2024-05-17\n210373\n92\n94\n['art pop', 'pop']\n0.20000\n0.747\n...\n0.123330\n0.007071\n0.042765\n0.548626\n0.067396\n0.112151\n0.500842\n0.387007\n0.963745\n0.036255\n\n\n2\nI Had Some Help (Feat. Morgan Wallen)\nI Had Some Help\nPost Malone\n2024-05-10\n178205\n91\n90\n['dfw rap', 'melodic rap', 'pop', 'rap']\n0.00757\n0.638\n...\n0.989839\n0.003102\n0.000821\n0.000706\n0.000557\n0.210037\n0.717910\n0.072052\n0.998456\n0.001544\n\n\n\n\n3 rows × 33 columns\n\n\n\n\nIn summary, the above code aims to collect and refine song lyrics by eliminating stopwords and conducting lemmatization. Subsequently, it employs pre-trained models for sentiment analysis to determine the prevailing emotion conveyed in the lyrics. Finally, the program compiles all this information into a dataframe for further analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#correlations-matrix",
    "href": "index.html#correlations-matrix",
    "title": "NLP Song Lyrics",
    "section": "Correlations Matrix",
    "text": "Correlations Matrix\nAfter completing the initial data analysis, we proceed with generating the Pearson correlations matrix using the Pandas command df.corr(). Subsequently, we visualize the matrix using the seaborn heatmap, providing a detailed understanding of the relationships between the various variables in our dataset.\n\ntrack_sentiment_df = df_final[['name', 'artist',\n           'acousticness', 'danceability', 'energy', 'instrumentalness', \n           'loudness', 'speechiness', 'tempo', 'valence', \n           'sadness', 'joy', 'love', 'anger', 'fear', 'surprise',\n           'LABEL_0', 'LABEL_1', 'LABEL_2', 'NEGATIVE', 'POSITIVE']]\n\n# Find the pearson correlations matrix\ncorr = track_sentiment_df.corr(method = 'pearson')\n\n\n\nThe code below produces a scatterplot that showcases the correlation between energy and fear. The x-axis represents the energy value, while the y-axis represents the fear sentiment. The size of each data point corresponds to the label indicating the neutral sentiment level, and its color represents the valence value. Moreover, each bubble contains its energy value within, allowing for a straightforward interpretation of the data.\n\n\nSimilarly, the scatterplot presented above utilizes the track sentiment data, comparing the energy and fear levels of the tracks based on valence and size.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#principal-component-analysis",
    "href": "index.html#principal-component-analysis",
    "title": "NLP Song Lyrics",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\nPrincipal Component Analysis (PCA) is a unsupervised dimension reduction algorithm. We implement PCA on a range of track audio features as well as emotional sentiments such as sadness, joy, love, anger, and more from our data. This lets us transform the data into fewer columns, reducing the dimensionality without losing significant information.\nAfter performing PCA on the data, we apply it to generate a biplot depicting the relationship between the features and tracks. This biplot quickly reveals any discernible patterns and clusters within the dataset.\n\nX_SMALL = df_final[['acousticness', 'danceability', 'energy', 'speechiness', \n                    'tempo', 'valence', 'sadness', 'joy', 'love', 'anger', \n                    'fear', 'surprise', 'name', 'LABEL_0', 'LABEL_1', 'LABEL_2']]\n\nWe use the PCA and StandardScaler modules from the sklearn library. First, we select the first 12 columns from our data subset and form a matrix, named \\(X_i\\). We then standardize the data. Next, we apply PCA to the standardized data, \\(X_{st}\\). Lastly, we save the obtained loadings and eigenvalues.\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Standard scaling track audio features\nX_i = X_SMALL.iloc[:,0:12]\nX_st =  StandardScaler().fit_transform(X_i)\n\n# Apply PCA to scaled data\npca = PCA()\npca_out = pca.fit(X_st)\n\n# component loadings\nloadings = pca_out.components_\n\n# get eigenvalues (variance explained by each PC)  \npca_out.explained_variance_\n\narray([2.61151346e+00, 1.81152715e+00, 1.33922867e+00, 1.31783191e+00,\n       1.14442842e+00, 9.59251161e-01, 8.69078284e-01, 7.57688171e-01,\n       6.51011595e-01, 4.99982382e-01, 2.88458789e-01, 5.55891815e-15])\n\n\nNext, the following code uses the PCA() function to calculate the PCA scores of the standardized data set, \\(X_{st}\\).\n\nfeatures = X_i.columns.values # Labels\ncomponents = pca.fit_transform(X_st) # PCA Score\nloadings = pca_out.components_.T * np.sqrt(pca_out.explained_variance_)\n\nA biplot is generated based on the PCA scores and loadings, and the column names of the \\(X_i\\) data frame are used as labels for the plot. The variance explained by the first two principal components are also displayed on the plot.\n\n\n                                                \n\n\nBelow is a preview of all the PCA clustered groups.\n\n\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\nPC11\nPC12\n\n\n\n\n0\n-1.255327\n-1.166254\n-0.226468\n-0.095443\n0.512157\n0.251976\n0.191732\n0.633547\n-0.228078\n0.038155\n-0.080939\n-1.867852e-08\n\n\n1\n1.106221\n-0.054969\n0.644421\n2.079536\n0.566187\n0.346209\n0.449961\n-0.656690\n-0.188145\n0.652280\n-0.584806\n-9.989372e-09\n\n\n2\n-1.720206\n-1.648513\n0.983419\n-0.934156\n-0.127514\n-0.277883\n-0.134462\n0.671739\n-0.405604\n-0.024465\n-0.029920\n2.470032e-08\n\n\n3\n-1.855349\n-1.099255\n0.249102\n-0.101427\n-0.526975\n0.617712\n-0.364594\n-0.379423\n0.116606\n0.561498\n0.613963\n-2.379668e-08\n\n\n4\n-1.652668\n0.276595\n0.710064\n-0.661191\n-0.173154\n0.807907\n-0.393728\n0.078094\n0.430236\n0.810153\n-0.139121\n-1.180899e-07\n\n\n\n\n\n\n\n\nThe variance ratios for the PCA output and the cumulative sum of the explained variance ratios are printed below. Specifically, the array displayed represents the amount of variability explained by each component.\n\nprint(pca_out.explained_variance_ratio_)\nprint('----')\nprint(pca_out.explained_variance_ratio_.cumsum())\n\n[2.13184773e-01 1.47879768e-01 1.09324790e-01 1.07578115e-01\n 9.34227281e-02 7.83062172e-02 7.09451660e-02 6.18520956e-02\n 5.31438037e-02 4.08148883e-02 2.35476562e-02 4.53789237e-16]\n----\n[0.21318477 0.36106454 0.47038933 0.57796744 0.67139017 0.74969639\n 0.82064156 0.88249365 0.93563746 0.97645234 1.         1.        ]\n\n\nThe loading vectors help visualize the relationship between the original variables and their respective components. These vectors represent the weights of the variables within a mathematical equation used to generate the principal components.\n\ndf_weights = pd.DataFrame(pca_out.components_.T, columns=df_pca.columns, index=X_i.columns)\ndf_weights\n\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\nPC11\nPC12\n\n\n\n\nacousticness\n0.358283\n0.104049\n-0.063878\n-0.015859\n-0.243579\n0.608952\n0.198491\n0.191712\n0.183645\n-0.538147\n-0.163837\n3.664172e-08\n\n\ndanceability\n-0.419590\n0.341618\n-0.156759\n0.092896\n0.004792\n0.292212\n-0.069513\n-0.301191\n-0.023869\n0.195202\n-0.674096\n-8.094544e-09\n\n\nenergy\n-0.270231\n-0.046466\n0.304788\n-0.412576\n0.311609\n-0.019222\n0.164241\n0.487791\n-0.429709\n-0.206228\n-0.268583\n1.015555e-08\n\n\nspeechiness\n-0.114283\n0.578280\n-0.083071\n0.024459\n-0.092389\n-0.160265\n-0.139969\n-0.251255\n-0.439345\n-0.482905\n0.319171\n2.271286e-08\n\n\ntempo\n0.130552\n0.161948\n0.453147\n-0.348590\n-0.047742\n-0.134351\n-0.641145\n-0.056571\n0.386878\n-0.128357\n-0.170662\n-1.620258e-08\n\n\nvalence\n-0.398480\n0.046868\n0.210691\n-0.100710\n0.071207\n0.636045\n-0.162503\n0.042369\n0.056184\n0.217912\n0.544074\n6.463812e-09\n\n\nsadness\n0.411517\n0.069542\n-0.103748\n-0.507468\n0.176455\n0.152737\n0.106654\n-0.342045\n-0.210846\n0.246653\n0.021472\n-5.185950e-01\n\n\njoy\n-0.418205\n-0.416517\n0.031391\n-0.013577\n-0.399918\n-0.076954\n-0.005649\n-0.136880\n0.053904\n-0.294254\n-0.021520\n-6.130827e-01\n\n\nlove\n-0.077398\n-0.038721\n-0.521160\n0.095973\n0.616436\n0.009760\n-0.330022\n0.197886\n0.233632\n-0.250531\n0.036381\n-2.546696e-01\n\n\nanger\n-0.110124\n0.569632\n0.025421\n-0.008922\n-0.118327\n-0.225066\n0.334545\n0.396342\n0.385516\n0.203134\n0.085264\n-3.631076e-01\n\n\nfear\n0.265825\n0.054301\n0.320958\n0.592996\n0.018068\n0.122371\n-0.293411\n0.241383\n-0.354671\n0.149231\n-0.099510\n-3.925677e-01\n\n\nsurprise\n-0.025291\n0.015145\n0.484562\n0.264578\n0.492208\n-0.012556\n0.391660\n-0.419788\n0.242568\n-0.242659\n0.013572\n-6.614867e-02",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#k-means-clustering",
    "href": "index.html#k-means-clustering",
    "title": "NLP Song Lyrics",
    "section": "K Means Clustering",
    "text": "K Means Clustering\n\n“Clustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\n\nIn the next step, we utilize K-means clustering on the dimensionally reduced data to investigate patterns and similarities among track audio features and sentiment. K-means is an unsupervised learning algorithm that aims to identify the optimal number of clusters (\\(K\\)) to group the data best. To help find the best \\(K\\) for the data, we employ the Elbow method.\nUsing K Means clustering, we choose to break the playlist into 3 smaller playlists.\nAs shown below, we employ the KMeans algorithm, obtained from the sklearn.cluster library, to cluster a collection of songs into distinct categories based on track features, such as their energy levels and sound qualities. Using three clusters, we apply this algorithm on the track features from the “playlist_tracks” subset of data, dropping the “artist” and “name” columns.\n\nfrom sklearn.cluster import KMeans\nplaylist_tracks = df_final[['name','acousticness','danceability','energy', 'liveness', \n                            'instrumentalness','speechiness','valence',\n                            'sadness', 'joy', 'love', 'anger', 'fear', ]]#'surprise'\n\nkmeans = KMeans(n_clusters = 3)\nkmeans.fit(playlist_tracks.drop(['name'], axis = 1))\n\nKMeans(n_clusters=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(n_clusters=3)\n\n\n\n\n                                                \n\n\n\nVisualizing the Clusters\nMoving forward, let’s look at differences in the audio features of each group.\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(playlist_tracks.drop(['name'], axis = 1))\nscaled_data = scaler.transform(playlist_tracks.drop(['name'], axis = 1))\n\n\n\nCode\nfrom sklearn.decomposition import PCA\npca = PCA(n_components =2)\npca.fit(scaled_data)\ndata_pca = pca.transform(scaled_data)\n\n\n\n\nText(0, 0.5, 'PC2: 0.150')\n\n\n\n\n\n\n\n\n\n\nplaylist_tracks['group'] = list(kmeans.labels_)\nplaylist_tracks = playlist_tracks.astype({'group': str})\n\nmeans = pd.DataFrame(index = range(0,3), \n                    columns = list(playlist_tracks[playlist_tracks['group'] == '0'].describe().loc['mean'].index))\nmeans.iloc[0] = playlist_tracks[playlist_tracks['group'] == '0'].describe().loc['mean']\nmeans.iloc[1] = playlist_tracks[playlist_tracks['group'] == '1'].describe().loc['mean']\nmeans.iloc[2] = playlist_tracks[playlist_tracks['group'] == '2'].describe().loc['mean']\nmeans\n\n\n\n\n\n\n\n\n\nacousticness\ndanceability\nenergy\nliveness\ninstrumentalness\nspeechiness\nvalence\nsadness\njoy\nlove\nanger\nfear\n\n\n\n\n0\n0.170163\n0.739071\n0.605643\n0.151\n0.004429\n0.094143\n0.544786\n0.077204\n0.119145\n0.111349\n0.317363\n0.345699\n\n\n1\n0.326517\n0.574083\n0.592333\n0.136058\n0.000019\n0.059392\n0.416917\n0.756223\n0.061522\n0.060179\n0.072008\n0.046813\n\n\n2\n0.126082\n0.714348\n0.666304\n0.145591\n0.042423\n0.0501\n0.650652\n0.047924\n0.825909\n0.04525\n0.057317\n0.020473\n\n\n\n\n\n\n\n\n\n\n\nOrganized Songs in a Playlist\nK-means is a clustering algorithm that tries to partition a set of points into K sets (clusters) such that the points in each cluster tend to be near each other. It is unsupervised because the points have no external classification.\nK means clustering is an unsupervised machine learning algorithm. This algorithm is used to divide the existing data points into classes. It is an eager learner algorithm, so we can’t skip the training phase.\nBelow, we import the Python pandas, matplotlib.pyplot, and sklearn libraries to our project. These tools help us perform various operations such as clustering, decomposition, and data visualization.\nWe then obtain a list of songs including their name and various attributes such as acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence, and loudness. Next, we gather helpful insights about these songs using the’ describe’ function.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import cluster, decomposition\n\nsongs = df_final[['name','acousticness', 'danceability', 'energy', 'instrumentalness', \n            'liveness', 'speechiness', 'valence',  'loudness_scaled', \n            'anger', 'love', 'sadness']]\nsongs.describe()\n\n\n\n\n\n\n\n\n\nacousticness\ndanceability\nenergy\ninstrumentalness\nliveness\nspeechiness\nvalence\nloudness_scaled\nanger\nlove\nsadness\n\n\n\n\ncount\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n49.000000\n\n\nmean\n0.187762\n0.687061\n0.630857\n0.021183\n0.144802\n0.064959\n0.563163\n0.641806\n0.135214\n0.067792\n0.229751\n\n\nstd\n0.196114\n0.149292\n0.134388\n0.125934\n0.099713\n0.050306\n0.232433\n0.213949\n0.233599\n0.163837\n0.333629\n\n\nmin\n0.000938\n0.264000\n0.386000\n0.000000\n0.029700\n0.026400\n0.155000\n0.000000\n0.000206\n0.000193\n0.001261\n\n\n25%\n0.035100\n0.625000\n0.507000\n0.000000\n0.089400\n0.036800\n0.337000\n0.565960\n0.003334\n0.003102\n0.015780\n\n\n50%\n0.107000\n0.689000\n0.640000\n0.000002\n0.110000\n0.050900\n0.604000\n0.686931\n0.038075\n0.006816\n0.052300\n\n\n75%\n0.261000\n0.787000\n0.729000\n0.000051\n0.151000\n0.068700\n0.738000\n0.785078\n0.127450\n0.029717\n0.314458\n\n\nmax\n0.799000\n0.943000\n0.946000\n0.879000\n0.549000\n0.270000\n0.945000\n1.000000\n0.993250\n0.992157\n0.998848\n\n\n\n\n\n\n\n\nExtracting the song labels from the dataset is the first crucial step. Then, we must select the appropriate features that will serve as inputs for the Affinity Propagation clustering algorithm from the scikit-learn library. During the clustering process, a preference value of -200 is used to ensure optimal performance. Once the data is inputted, the algorithm is trained to achieve the desired outcome.\n\nlabels = songs.values[:,0]\nX = songs.values[:,1:12]\nkmeans = cluster.AffinityPropagation()\nkmeans.fit(X)\n\nAffinityPropagation()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.AffinityPropagationAffinityPropagation()\n\n\nThe script below utilizes a dictionary called “predictions” to keep track of the outcomes of a comparison process between two lists: “kmeans.predict(X)” and “labels”. For each new value, a unique key is generated in the dictionary with the corresponding value from the “labels” list appended to the key’s list of values.\nAfter sorting all values into their designated keys, we proceed to display each key alongside its relevant values. The output displays each category and the corresponding songs it contains.\n\npredictions = {}\nfor p,n in zip(kmeans.predict(X),labels):\n    if not predictions.get(p):\n        predictions[p] = []\n        \n    predictions[p] += [n]\n\nfor p in predictions:\n    print(\"Category\",p)\n    print(\"-----\")\n    for n in predictions[p]:\n        print(n)\n    print(\"\")\n\nCategory 0\n-----\nEspresso\nI Had Some Help (Feat. Morgan Wallen)\nToo Sweet\nMILLION DOLLAR BABY\nA Bar Song (Tipsy)\nLUNCH\ni like the way you kiss me\nPlease Please Please\nEnd of Beginning\nHoudini\nGood Luck, Babe!\nBelong Together\nSlow It Down\nWater\nMiles On It\nyes, and?\nTell Ur Girlfriend\nSanta\nWhatever\nIllusion\nI Don't Wanna Wait\nJump\nMagnetic\n\nCategory 1\n-----\nBIRDS OF A FEATHER\nFortnight (feat. Post Malone)\nScared To Start\nGata Only\n\nCategory 3\n-----\nwe can't be friends (wait for your love)\nBeautiful Things\nNot Like Us\nPink Skies\nTEXAS HOLD 'EM\nOne Of The Girls (with JENNIE, Lily Rose Depp)\nI Remember Everything (feat. Kacey Musgraves)\n\nCategory 2\n-----\nLose Control\nI Can Do It With a Broken Heart\nSaturn\nAustin\nStargazing\nStick Season\nFeel It - From The Original Series “Invincible”\nobsessed\n\nCategory 5\n-----\ngreedy\nBAND4BAND (feat. Lil Baby)\n\nCategory 4\n-----\nNasty\none of wun\nredrum\n\nCategory 6\n-----\nLovin On Me\n\nCategory 7\n-----\nCHIHIRO\n\n\n\nThe script successfully categorized the playlist into 6 distinct groups based on shared features, resulting in a diverse selection of songs within each category.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#supervised-learning-similarity-search",
    "href": "index.html#supervised-learning-similarity-search",
    "title": "NLP Song Lyrics",
    "section": "Supervised Learning: Similarity Search",
    "text": "Supervised Learning: Similarity Search\nBelow, we create a query to retrieve similar elements based on Euclidean distance. In mathematics, the Euclidean distance between two points is the length of the line segment between the two points. In this sense, the closer the distance is to 0, the more similar the songs are.\n\nKNN Algorithm\nK-nearest neighbors is a classification (or regression) algorithm that in order to determine the classification of a point, combines the classification of the K nearest points. It is supervised because you are trying to classify a point based on the known classification of other points.\nTo obtain a string search for a song, utilize the getMusicName function shown below, which returns the artist and song name.\nThe k-Nearest Neighbors (KNN) algorithm searches for k similar elements based on a query point at the center within a predefined radius. We execute the KNN algorithm using the knnQuery function defined below, which takes a query point, a set of characteristic points, and a value for k. It computes the sum of squared differences between each data and query point, followed by the calculation of the Euclidean distance between them. The function then arranges the points by distance and returns the k closest and farthest points.\nThe querySimilars function then removes the query point and executes the KNN algorithm on the remaining points, returning the k most similar points to the query point based on the specified columns, function, and parameter.\n\n# Get a song string search\ndef getMusicName(elem):\n    return f\"{elem['artist']} - {elem['name']}\"\n\ndef knnQuery(queryPoint, arrCharactPoints, k):\n    queryVals = queryPoint.tolist()\n    distVals = []\n    \n    # Copy of dataframe indices and data\n    tmp = arrCharactPoints.copy(deep = True)  \n    for index, row in tmp.iterrows():\n        feat = row.values.tolist()\n        \n        # Calculate sum of squared differences\n        ssd = sum(abs(feat[i] - queryVals[i]) ** 2 for i in range(len(queryVals)))\n        \n        # Get euclidean distance\n        distVals.append(ssd ** 0.5)\n        \n    tmp['distance'] = distVals\n    tmp = tmp.sort_values('distance')\n    \n    # K closest and furthest points\n    return tmp.head(k).index, tmp.tail(k).index\n\n\n# Execute KNN removing the query point\ndef querySimilars(df, columns, idx, func, param):\n    arr = df[columns].copy(deep = True)\n    queryPoint = arr.loc[idx]\n    arr = arr.drop([idx])\n    return func(queryPoint, arr, param)\n\nKNN Query Example.\nWe now establish a function that creates customized query points and alters the data columns, allowing for further exploration of various options. To illustrate, the code snippet below chooses a particular group of song features and then seeks out the top k values within that feature set that are equal to one.\nTo begin, we create a scaler utilizing the preprocessing library from sklearn. It’s worth noting that all the feature values fall within the range of 0 and 1, except for loudness. As a result, we need to scale loudness to conform to the same range.\nLet’s search for \\(k=3\\) similar songs to a query point \\(\\textrm{songIndex} = 6\\).\n\n# Select song and column attributes\nsongIndex = 4 # query point\ncolumns = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', \n           'loudness_scaled', 'tempo', \n           'speechiness', 'valence']\n\n# Set query parameters\nfunc, param = knnQuery,3\n\n# Implement query\nresponse = querySimilars(df, columns, songIndex, func, param)\n\nprint(\"---- Query Point ----\")\nprint(getMusicName(df.loc[songIndex]))\nprint('---- k = 3 similar songs ----')\nfor track_id in response[0]:\n    track_name = getMusicName(df.loc[track_id])\n    print(track_name)\nprint('---- k = 3 nonsimilar songs ----')\nfor track_id in response[1]:\n    track_name = getMusicName(df.loc[track_id])\n    print(track_name)\n\n---- Query Point ----\nTommy Richman - MILLION DOLLAR BABY\n---- k = 3 similar songs ----\nGunna - one of wun\nCentral Cee - BAND4BAND (feat. Lil Baby)\nLay Bankz - Tell Ur Girlfriend\n---- k = 3 nonsimilar songs ----\nTaylor Swift - Fortnight (feat. Post Malone)\nShaboozey - A Bar Song (Tipsy)\nZach Bryan - I Remember Everything (feat. Kacey Musgraves)\n\n\nThe code below implements the same idea as above, but queries each track in a given playlist instead of a single defined query point.\nTo keep track of the number of songs that are similar and those that are not, we use two dictionaries: similar_count” and “nonsimilar_count”. To do this, we create a loop that goes through the data, running the querySimilars function on each track. A loop then processes “similar” and “non-similar” songs from the results of the query, stored in the “response” variable. If a “similar” song is found, its name is retrieved using the getMusicName function. The song’s name is then added to the “similar_count” dictionary with a count of 1, or incremented if it already exists.\nThe same process is repeated for the “non-similar” songs, except the count is added to the “nonsimilar_count” dictionary instead.\n\nsimilar_count = {} # Similar songs count\nnonsimilar_count = {} # Non-similar songs count\n\nfor track_index in df.index:\n    # Implement query\n    response = querySimilars(df, columns, track_index, func, param)\n    \n    # Get similar songs\n    for similar_index in response[0]:\n        track = getMusicName(df.loc[similar_index])\n        if track in similar_count:\n            similar_count[track] += 1\n        else:\n            similar_count[track] = 1\n    \n    # Get non-similar songs\n    for nonsimilar_index in response[1]:\n        track = getMusicName(df.loc[nonsimilar_index])\n        if track in nonsimilar_count:\n            nonsimilar_count[track] += 1\n        else:\n            nonsimilar_count[track] = 1\n\nNext, we display both the non-similar and similar songs with their respective track name and count.\n\nnonsimilar = dict(sorted(nonsimilar_count.items(), key=lambda item: item[1], reverse=True))\nprint('---- NON SIMILAR SONG COUNTS ----')\nfor track_name, track_count in nonsimilar.items():\n    if track_count &gt;= 8:\n        print(track_name, ':', track_count)\n\nsimilar = dict(sorted(similar_count.items(), key=lambda item: item[1], reverse=True))\nprint('\\n---- SIMILAR SONG COUNTS ----')\nfor track_name, track_count in similar.items():\n    if track_count &gt;= 5:\n        print(track_name, ':', track_count)\n\n---- NON SIMILAR SONG COUNTS ----\nTaylor Swift - Fortnight (feat. Post Malone) : 39\nBenson Boone - Slow It Down : 37\nSZA - Saturn : 32\nZach Bryan - I Remember Everything (feat. Kacey Musgraves) : 17\nShaboozey - A Bar Song (Tipsy) : 12\nThe Weeknd - One Of The Girls (with JENNIE, Lily Rose Depp) : 10\n\n---- SIMILAR SONG COUNTS ----\nNoah Kahan - Stick Season : 5\nHozier - Too Sweet : 5\n\n\nAs shown above, the code snippet arranges the “nonsimilar_count” dictionary in a descending sequence, followed by presenting the tracks with the highest non-similar query counts. We repeat the same process for songs that are similar from the “similar_count” dictionary.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/01_data.html",
    "href": "01_sentiment_analysis/01_data.html",
    "title": "Extracting Spotify Data",
    "section": "",
    "text": "Getting started, we want to extract data for a set of tracks within one of Spotify’s top-featured playlists. Leveraging the Spotify Web API, we can seamlessly obtain detailed data for a song, such as the performing artist, the album it belongs to, its release date, popularity, and audio features like danceability, energy, and tempo.\nPython libraries like spotipy offer a user-friendly way to interact with the Spotify API, offering a range of functions that streamline tasks like API authentication, retrieving playlist data, and obtaining information about any given song.\n\nAccessing the Spotify Web API\nTo access data from Spotify, we import the spotipy library and the SpotifyClientCredentials module. Additionally, we utilize the pandas package for data manipulation and display. In order to authenticate our access to the Spotify API, we must provide our client ID and client secret to a client credentials manager. Once authenticated, we can use the spotipy module to interact with the Spotify API and retrieve data.\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport pandas as pd\n\nclient_id = \"xxx\"\nclient_secret = \"xxx\"\nmy_auth = SpotifyClientCredentials(client_id, client_secret)\nsp = spotipy.Spotify(auth_manager=my_auth)\n\n\nSpotify’s Featured Playlists\nLet’s take a look at the popular Spotify playlists. Below, the code retrieves a range of Spotify playlists and generates a dataframe containing details for each playlist, including its name, ID, description, thumbnail, total number of tracks, and follower count. The resulting dataframe is displayed as an HTML table.\n\nusername = \"spotify\"\nspotify_playlists = sp.user_playlists(username)\ntop_playlists = get_top_playlists(username, 6)\n\nThe function get_top_playlists retrieves all playlists for a given user and returns the playlists with the most followers. Specifically, the function gets all playlists from a given user, iterating over each playlist item to extract the thumbnail image URL, the playlist name, ID, description, total number of tracks, and follower count for the playlist. It then creates a DataFrame from the playlist data, sorts the DataFrame by the number of followers in descending order, and returns the top playlists with the most followers.\n\n\n\n\n\n\n\nthumbnail\nname\nid\ndescription\ntracks\nfollowers\n\n\n\n\n0\n\nToday’s Top Hits\n37i9dQZF1DXcBWIGoYBM5M\nSabrina Carpenter is on top of the Hottest 50!\n50\n34638307\n\n\n1\n\nRapCaviar\n37i9dQZF1DX0XUsuxWHRQd\nMusic from Central Cee, Future, Metro Boomin and Kendrick Lamar.\n51\n15929532\n\n\n3\n\nViva Latino\n37i9dQZF1DX10zKzsJ2jva\nToday's top Latin hits, elevando nuestra música. Cover: Trueno\n50\n15093527\n\n\n12\n\nAll Out 2000s\n37i9dQZF1DX4o1oenSJRJd\nThe biggest songs of the 2000s. Cover: The Killers\n150\n12324392\n\n\n7\n\nRock Classics\n37i9dQZF1DWXRqgorJj26U\nRock legends & epic songs that continue to inspire generations. Cover: The Rolling Stones\n200\n12167228\n\n\n14\n\nAll Out 80s\n37i9dQZF1DX4UtSsGT1Sbe\nThe biggest songs of the 1980s. Cover: Bruce Springsteen\n150\n11278061\n\n\n\n\n\n\n\n\n\n\nExtracting Tracks From a Playlist\nThe following script enables the compilation of song and artist data from any Spotify playlist through its URI. To analyze a particular playlist, simply copy the URI from the Spotify Player interface and input it into the function defined below. The get_playlist_tracks method returns a complete list of track IDs and corresponding artists from the selected playlist.\n\ndef get_playlist_tracks(playlist_URI):\n    tracks = []\n    results = sp.playlist_tracks(playlist_URI)\n    tracks = results[\"items\"]\n    while results[\"next\"]:\n        results = sp.next(results)\n        tracks.extend(results[\"items\"])\n    return tracks\n\n\nExtracting Features from Tracks\nThe following script utilizes Spotify’s API to extract further details about each song within the playlist. It obtains metadata such as the track name, the artist it’s sung by, the album it belongs to, the release date, and track features such as danceability, tempo, and popularity.\n\ndef playlist_features(id, artist_id, playlist_id):\n    meta = sp.track(id)\n    audio_features = sp.audio_features(id)\n    artist_info = sp.artist(artist_id)\n    playlist_info = sp.playlist(playlist_id)\n\n    # print(audio_features)\n\n    if audio_features[0] is None:\n        return None\n    \n    \n\n    name = meta['name']\n    track_id = meta['id']\n    album = meta['album']['name']\n    artist = meta['album']['artists'][0]['name']\n    artist_id = meta['album']['artists'][0]['id']\n    release_date = meta['album']['release_date']\n    length = meta['duration_ms']\n    popularity = meta['popularity']\n\n    artist_pop = artist_info[\"popularity\"]\n    artist_genres = artist_info[\"genres\"]\n    artist_followers = artist_info[\"followers\"]['total']\n\n    acousticness = audio_features[0]['acousticness']\n    danceability = audio_features[0]['danceability']\n    energy = audio_features[0]['energy']\n    instrumentalness = audio_features[0]['instrumentalness']\n    liveness = audio_features[0]['liveness']\n    loudness = audio_features[0]['loudness']\n    speechiness = audio_features[0]['speechiness']\n    tempo = audio_features[0]['tempo']\n    valence = audio_features[0]['valence']\n    key = audio_features[0]['key']\n    mode = audio_features[0]['mode']\n    time_signature = audio_features[0]['time_signature']\n    \n    playlist_name = playlist_info['name']\n\n    return [name, track_id, album, artist, artist_id, release_date, length, popularity, \n            artist_pop, artist_genres, artist_followers, acousticness, danceability, \n            energy, instrumentalness, liveness, loudness, speechiness, \n            tempo, valence, key, mode, time_signature, playlist_name]\n\nChoose a specific playlist to analyze by copying the URL from the Spotify Player interface. Using that link, the playlist_tracks method retrieves a list of IDs and corresponding artists for each track from the playlist. Specifically, we analyze Spotify’s Today’s Top Hits playlist.\n\nplaylist_links = [top_playlists['id'][0]]\n\nfor playlist_URI in playlist_links:\n    # playlist_URI = link.split(\"/\")[-1].split(\"?\")[0]\n    \n    all_tracks = [  # Loop over track ids\n    playlist_features(i[\"track\"][\"id\"], i[\"track\"][\"artists\"][0][\"uri\"], playlist_URI)\n    for i in get_playlist_tracks(playlist_URI)\n]\n\nPutting it all together, the get_playlist_tracks function retrieves basic details for each song in a specified Spotify playlist using its URI. The playlist_features function then iterates through these tracks using their IDs to extract additional information, such as danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, and more. From there, we create a Pandas dataframe by passing in the extracted information.\n\nLoudness Scaled\n\n# Loudness Scaled\nfrom sklearn import preprocessing \n\nscaler = preprocessing.MinMaxScaler()\n# scale loudness to fit the same range [0, 1]\nloudness2 = df[\"loudness\"].values\nloudness_scaled=scaler.fit_transform(loudness2.reshape(-1, 1))\ndf['loudness_scaled'] = loudness_scaled\n\n\n\n\n\n\n\n\n\n\n\nname\ntrack_id\nalbum\nartist\nartist_id\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\n...\nliveness\nloudness\nspeechiness\ntempo\nvalence\nkey\nmode\ntime_signature\nplaylist\nloudness_scaled\n\n\n\n\n0\nEspresso\n2qSkIjg1o9h3YT9RAgYN75\nEspresso\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-04-12\n175459\n95\n87\n[pop]\n...\n0.1850\n-5.478\n0.0285\n103.969\n0.690\n0\n1\n4\nToday’s Top Hits\n0.721830\n\n\n1\nBIRDS OF A FEATHER\n6dOtVTDdiauQNBQEDOtlAB\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n210373\n92\n94\n[art pop, pop]\n...\n0.1170\n-10.171\n0.0358\n104.978\n0.438\n2\n1\n4\nToday’s Top Hits\n0.241531\n\n\n2\nI Had Some Help (Feat. Morgan Wallen)\n7221xIgOnuakPdLqT0F3nP\nI Had Some Help\nPost Malone\n246dkjvS1zLTtiykXe5h60\n2024-05-10\n178205\n91\n90\n[dfw rap, melodic rap, pop, rap]\n...\n0.2450\n-4.860\n0.0264\n127.986\n0.731\n7\n1\n4\nToday’s Top Hits\n0.785078\n\n\n3\nToo Sweet\n4IadxL6BUymXlh8RCJJu7T\nUnheard\nHozier\n2FXC3k01G6Gw61bmprjgqS\n2024-03-22\n251424\n80\n85\n[irish singer-songwriter, modern rock, pov: in...\n...\n0.0398\n-5.505\n0.0412\n117.038\n0.934\n10\n1\n4\nToday’s Top Hits\n0.719067\n\n\n4\nMILLION DOLLAR BABY\n7fzHQizxTqy8wTXwlrgPQQ\nMILLION DOLLAR BABY\nTommy Richman\n1WaFQSHVGZQJTbf0BdxdNo\n2024-04-26\n155151\n92\n82\n[chill abstract hip hop]\n...\n0.0680\n-5.106\n0.0436\n138.003\n0.927\n1\n0\n4\nToday’s Top Hits\n0.759902\n\n\n\n\n5 rows × 25 columns",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Extracting Spotify Data</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html",
    "href": "01_sentiment_analysis/02_nlp.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "Scraping the Web\nTo get started, the script below imports lyricsgenius, a fundamental package libary allowing for web scraping of the Genius Lyrics website to retrieve the lyrics of any given song. Through the initialization of the genius variable, one can access the Genius API and retrieve the lyrics of any given song, such as “Too Many Nights” by Metro Boomin.\nimport lyricsgenius\n\ngenius = lyricsgenius.Genius(\"epFCxujgBe-Y6WrkZedI8kerKxiCpR6Rh0DAHYNlKDf9B4H1nXTdZIkj7krNUHVV\")\nsong = genius.search_song(\"Too Many Nights\", \"Metro Boomin\")\n\nSearching for \"Too Many Nights\" by Metro Boomin...\nDone.\nFirst, we define a function that retrieves the lyrics for any song and artist from the Genius database. As shown below, it first searches for the track using the provided name and artist and then extracts the lyrics from the search results.\ndef get_song_lyrics(song_name, song_artist):\n    song_genius = genius.search_song(song_name, song_artist)\n    song_lyrics = song_genius.lyrics.partition(\"Lyrics\")[2]\n    # Remove any numbers followed by 'Embed'\n    song_lyrics = re.sub(r\"[\\[].*?[\\]]|\\d+Embed\", \"\", song_lyrics)\n    # Remove text between square brackets\n    song_lyrics = re.sub(r\"(\\-[A-Za-z]+\\-)\", \"\", song_lyrics)\n    song_lyrics = re.sub(r'\\d+', '', song_lyrics)\n\n    return song_lyrics",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html#sentiment-analysis",
    "href": "01_sentiment_analysis/02_nlp.html#sentiment-analysis",
    "title": "Natural Language Processing",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nSubsequently, the process involves the implementation of pipeline classes to carry out predictions using models accessible in the Hub. The code imports and employs multiple transformer models specifically designed for text classification and sentiment analysis. Specifically, the following procedure creates three distinct pipelines, each equipped with different models that facilitate the assessment of emotions and sentiment in textual content.\n\nimport transformers\nfrom transformers import pipeline\n\n# Initialize Genius API and sentiment classifiers\nclassifiers = [\n    pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True),\n    pipeline(\"text-classification\", model='cardiffnlp/twitter-roberta-base-sentiment', return_all_scores=True),\n    pipeline(\"sentiment-analysis\", return_all_scores=True)\n]\n\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\nThe get_lyric_sentiment function takes in pre-processed lyrics as input and produces a dictionary of sentiment scores. It leverages three distinct classifiers to calculate the scores and aggregates them into a final result. For instance, one of these classifiers is the distilbert-base-uncased-emotion model, specifically trained to detect “emotions in texts such as sadness, joy, love, anger, fear, and surprise”.\n\n# Function to perform sentiment analysis\ndef get_lyric_sentiment(lyrics, classifiers):\n    text = ' '.join(lyrics)\n    scores = {}\n    for classifier in classifiers:\n        try:\n            predictions = classifier(text, truncation=True)\n            for prediction in predictions[0]:\n                scores[prediction['label']] = prediction['score']\n        except Exception as e:\n            print(f\"Error during sentiment analysis: {e}\")\n    return scores\n\nIf the lyric sequence contains more than 512 tokens, it will trigger an error message indicating an exception encountered in the ‘embeddings’ layer. However, we have implemented measures to properly manage lyric sequences that exceed 512 words in the function mentioned above.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html#putting-it-all-together",
    "href": "01_sentiment_analysis/02_nlp.html#putting-it-all-together",
    "title": "Natural Language Processing",
    "section": "Putting it All Together",
    "text": "Putting it All Together\nTo summarize, the code efficiently collects data and performs text analysis on every song in a playlist. Specifically, it systematically processes a list of tracks and corresponding artists while simultaneously conducting a thorough cleaning procedure on the lyrics. The cleaning process involves removing all nonessential characters, resulting in a more precise depiction of the song’s content. The outcome is a comprehensive frequency analysis of each word in a song’s lyrics, providing deeper insights into the overall conveyed message.\nAdditionally, the program computes a sentiment score for each song based on the lyrics, indicating whether the lyrics are positive, negative, or neutral. It also collects information about the song and artist, such as the release date, length, popularity, and genre. Finally, the program compiles all this information into a dataframe for further analysis.\n\ntrack_data = []\nfor i, track in all_tracks.iterrows():\n\n    song_name = track[\"name\"] #.partition(\" (\")[0]\n    song_name = track['name'].partition(\" (with\")[0]\n    song_name = song_name.partition(\" - From\")[0]\n    \n    artist_name = track[\"artist\"]\n\n    try:\n        track_lyrics = clean_song_lyrics(song_name, artist_name)\n        stopwords_removed = remove_stopwords_lyrics(track_lyrics)\n        lemmatized = word_lemmatize(stopwords_removed)\n\n        sentiment_scores = get_lyric_sentiment(stopwords_removed, classifiers)\n\n        track_info = track.to_dict()\n        track_info.update(sentiment_scores)\n\n        track_info[\"lyrics\"] = track_lyrics\n        track_info[\"stopwords_removed\"] = stopwords_removed\n        track_info[\"lemmatized\"] = lemmatized\n\n        track_data.append(track_info)\n\n    except Exception as e:\n        print(f\"Error processing track {track['name']} by {track['artist']}: {e}\")\n\ndf_tracks = pd.DataFrame(track_data)\n\nSearching for \"Espresso\" by Sabrina Carpenter...\nDone.\nSearching for \"BIRDS OF A FEATHER\" by Billie Eilish...\nDone.\nSearching for \"I Had Some Help (Feat. Morgan Wallen)\" by Post Malone...\nDone.\nSearching for \"Too Sweet\" by Hozier...\nDone.\nSearching for \"MILLION DOLLAR BABY\" by Tommy Richman...\nDone.\nSearching for \"we can't be friends (wait for your love)\" by Ariana Grande...\nDone.\nSearching for \"A Bar Song (Tipsy)\" by Shaboozey...\nDone.\nSearching for \"LUNCH\" by Billie Eilish...\nDone.\nSearching for \"Fortnight (feat. Post Malone)\" by Taylor Swift...\nDone.\nSearching for \"Beautiful Things\" by Benson Boone...\nDone.\nSearching for \"i like the way you kiss me\" by Artemas...\nDone.\nSearching for \"Please Please Please\" by Sabrina Carpenter...\nDone.\nSearching for \"End of Beginning\" by Djo...\nDone.\nSearching for \"Houdini\" by Eminem...\nDone.\nSearching for \"Lose Control\" by Teddy Swims...\nDone.\nSearching for \"Not Like Us\" by Kendrick Lamar...\nDone.\nError during sentiment analysis: The expanded size of the tensor (529) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 529].  Tensor sizes: [1, 514]\nSearching for \"Good Luck, Babe!\" by Chappell Roan...\nDone.\nSearching for \"I Can Do It With a Broken Heart\" by Taylor Swift...\nDone.\nSearching for \"Belong Together\" by Mark Ambor...\nDone.\nSearching for \"Saturn\" by SZA...\nDone.\nSearching for \"Slow It Down\" by Benson Boone...\nDone.\nSearching for \"Austin\" by Dasha...\nDone.\nSearching for \"Stargazing\" by Myles Smith...\nDone.\nSearching for \"Pink Skies\" by Zach Bryan...\nDone.\nSearching for \"Stick Season\" by Noah Kahan...\nDone.\nSearching for \"greedy\" by Tate McRae...\nDone.\nSearching for \"Scared To Start\" by Michael Marcagi...\nDone.\nSearching for \"Nasty\" by Tinashe...\nDone.\nSearching for \"Water\" by Tyla...\nDone.\nSearching for \"Gata Only\" by FloyyMenor...\nDone.\nSearching for \"Miles On It\" by Marshmello...\nDone.\nSearching for \"yes, and?\" by Ariana Grande...\nDone.\nSearching for \"TEXAS HOLD 'EM\" by Beyoncé...\nDone.\nSearching for \"BAND4BAND (feat. Lil Baby)\" by Central Cee...\nDone.\nSearching for \"Feel It\" by d4vd...\nDone.\nSearching for \"One Of The Girls\" by The Weeknd...\nDone.\nSearching for \"Tell Ur Girlfriend\" by Lay Bankz...\nDone.\nSearching for \"Lovin On Me\" by Jack Harlow...\nDone.\nSearching for \"Santa\" by Rvssian...\nDone.\nSearching for \"CHIHIRO\" by Billie Eilish...\nDone.\nSearching for \"Whatever\" by Kygo...\nDone.\nSearching for \"Illusion\" by Dua Lipa...\nDone.\nSearching for \"I Don't Wanna Wait\" by David Guetta...\nDone.\nSearching for \"Whatever She Wants\" by Bryson Tiller...\nError processing track Whatever She Wants by Bryson Tiller: Request timed out:\nHTTPSConnectionPool(host='genius.com', port=443): Read timed out. (read timeout=5)\nSearching for \"Jump\" by Tyla...\nDone.\nSearching for \"I Remember Everything (feat. Kacey Musgraves)\" by Zach Bryan...\nDone.\nError during sentiment analysis: The expanded size of the tensor (517) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 517].  Tensor sizes: [1, 514]\nSearching for \"one of wun\" by Gunna...\nDone.\nSearching for \"obsessed\" by Olivia Rodrigo...\nDone.\nSearching for \"Magnetic\" by ILLIT...\nDone.\nSearching for \"redrum\" by 21 Savage...\nDone.\n\n\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n\n\n\n#df_tracks = pd.DataFrame(track_data)\ndf_tracks.to_csv(\"../assets/data/all_tracks+lyrics.csv\", index=False)\n\n\ndf_tracks\n\n\n\n\n\n\n\n\n\nname\ntrack_id\nalbum\nartist\nartist_id\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\n...\nfear\nsurprise\nLABEL_0\nLABEL_1\nLABEL_2\nNEGATIVE\nPOSITIVE\nlyrics\nstopwords_removed\nlemmatized\n\n\n\n\n0\nEspresso\n2qSkIjg1o9h3YT9RAgYN75\nEspresso\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-04-12\n175459\n95\n87\n['pop']\n...\n0.046130\n0.005205\n0.058558\n0.745153\n0.196289\n0.988320\n0.011680\n[now, he, is, thinking, about, me, every, nigh...\n[thinking, every, night, sweet, guess, say, sl...\n[think, every, night, sweet, guess, say, sleep...\n\n\n1\nBIRDS OF A FEATHER\n6dOtVTDdiauQNBQEDOtlAB\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n210373\n92\n94\n['art pop', 'pop']\n...\n0.548626\n0.067396\n0.112151\n0.500842\n0.387007\n0.963745\n0.036255\n[i, want, you, to, stay, i, want, you, to, sta...\n[want, stay, want, stay, til, grave, til, rot,...\n[want, stay, want, stay, til, grave, til, rot,...\n\n\n2\nI Had Some Help (Feat. Morgan Wallen)\n7221xIgOnuakPdLqT0F3nP\nI Had Some Help\nPost Malone\n246dkjvS1zLTtiykXe5h60\n2024-05-10\n178205\n91\n90\n['dfw rap', 'melodic rap', 'pop', 'rap']\n...\n0.000706\n0.000557\n0.210037\n0.717910\n0.072052\n0.998456\n0.001544\n[you, got, a, got, ta, nerve, do, not, you, ba...\n[got, got, ta, nerve, baby, hit, curb, made, t...\n[get, get, ta, nerve, baby, hit, curb, make, t...\n\n\n3\nToo Sweet\n4IadxL6BUymXlh8RCJJu7T\nUnheard\nHozier\n2FXC3k01G6Gw61bmprjgqS\n2024-03-22\n251424\n80\n85\n['irish singer-songwriter', 'modern rock', 'po...\n...\n0.002293\n0.001093\n0.120370\n0.648945\n0.230685\n0.984314\n0.015686\n[it, can, not, be, said, i, am, an, early, bir...\n[said, early, bird, clock, say, word, baby, ne...\n[say, early, bird, clock, say, word, baby, nev...\n\n\n4\nMILLION DOLLAR BABY\n7fzHQizxTqy8wTXwlrgPQQ\nMILLION DOLLAR BABY\nTommy Richman\n1WaFQSHVGZQJTbf0BdxdNo\n2024-04-26\n155151\n92\n82\n['chill abstract hip hop']\n...\n0.025805\n0.003822\n0.336834\n0.601042\n0.062124\n0.993108\n0.006892\n[do, it, baby, do, what, i, should, think, do,...\n[baby, think, baby, could, think, baby, think,...\n[baby, think, baby, could, think, baby, think,...\n\n\n5\nwe can't be friends (wait for your love)\n46kspZSY3aKmwQe7O77fCC\neternal sunshine\nAriana Grande\n66CXWjxzNUsdJxJ2JdwvnR\n2024-03-08\n228639\n83\n90\n['pop']\n...\n0.000605\n0.000460\n0.063339\n0.507926\n0.428735\n0.996296\n0.003704\n[i, did, not, think, you, would, understand, m...\n[think, would, understand, could, ever, even, ...\n[think, would, understand, could, ever, even, ...\n\n\n6\nA Bar Song (Tipsy)\n2FQrifJ1N335Ljm3TjTVVf\nA Bar Song (Tipsy)\nShaboozey\n3y2cIKLjiOlp1Np37WiUdH\n2024-04-12\n171291\n90\n80\n['pop rap']\n...\n0.009928\n0.003751\n0.057218\n0.763994\n0.178788\n0.994249\n0.005751\n[my, baby, want, a, barking, she, is, been, te...\n[baby, want, barking, telling, night, long, ga...\n[baby, want, bark, tell, night, long, gasoline...\n\n\n7\nLUNCH\n629DixmZGHc7ILtEntuiWE\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n179586\n92\n94\n['art pop', 'pop']\n...\n0.004807\n0.005700\n0.226971\n0.703515\n0.069515\n0.995480\n0.004520\n[oh, mmmm, i, could, eat, that, girl, for, lun...\n[mmmm, could, eat, girl, lunch, dances, tongue...\n[mmmm, could, eat, girl, lunch, dance, tongue,...\n\n\n8\nFortnight (feat. Post Malone)\n2OzhQlSqBEmt7hmkYxfT6m\nTHE TORTURED POETS DEPARTMENT\nTaylor Swift\n06HL4z0CvFAxyc27GXpf02\n2024-04-18\n228965\n89\n100\n['pop']\n...\n0.018662\n0.010463\n0.575611\n0.374097\n0.050291\n0.991912\n0.008088\n[i, was, supposed, to, be, sent, away, i, shou...\n[supposed, sent, away, taken, away, forgot, co...\n[suppose, send, away, take, away, forgot, come...\n\n\n9\nBeautiful Things\n6tNQ70jh4OwmPGpYy6R2o9\nBeautiful Things\nBenson Boone\n22wbnEMDvgVIAGdFeek6ET\n2024-01-18\n180304\n88\n85\n['singer-songwriter pop']\n...\n0.996488\n0.000843\n0.033857\n0.318134\n0.648009\n0.012351\n0.987649\n[for, a, while, there, it, was, rough, but, la...\n[rough, lately, better, last, four, cold, reme...\n[rough, lately, well, last, four, cold, rememb...\n\n\n10\ni like the way you kiss me\n2GxrNKugF82CnoRFbQfzPf\ni like the way you kiss me\nArtemas\n0PCCGZ0wGLizHt2KZ7hhA2\n2024-03-19\n142514\n92\n81\n[]\n...\n0.001377\n0.001145\n0.034661\n0.521730\n0.443609\n0.984495\n0.015505\n[i, like, the, way, you, kiss, me, i, like, th...\n[like, way, kiss, like, way, uh, like, way, ki...\n[like, way, kiss, like, way, uh, like, way, ki...\n\n\n11\nPlease Please Please\n5N3hjp1WNayUPZrA8kJmJP\nPlease Please Please\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-06-06\n186365\n83\n87\n['pop']\n...\n0.000562\n0.000837\n0.269767\n0.516786\n0.213447\n0.825784\n0.174216\n[i, know, i, have, good, judgment, i, know, i,...\n[know, good, judgment, know, good, taste, funn...\n[know, good, judgment, know, good, taste, funn...\n\n\n12\nEnd of Beginning\n3qhlB30KknSejmIvZZLjOD\nDECIDE\nDjo\n5p9HO3XC5P3BLxJs5Mtrhm\n2022-09-16\n159245\n90\n77\n['pov: indie', 'psychedelic pop']\n...\n0.018631\n0.004027\n0.159378\n0.691760\n0.148862\n0.964887\n0.035113\n[just, one, more, tear, to, cry, one, teardrop...\n[one, tear, cry, one, teardrop, eye, better, s...\n[one, tear, cry, one, teardrop, eye, well, sav...\n\n\n13\nHoudini\n2HYFX63wP3otVIvopRS99Z\nHoudini\nEminem\n7dGJo4pcD2V6oG8kP0tJRR\n2024-05-31\n227239\n88\n90\n['detroit hip hop', 'hip hop', 'rap']\n...\n0.059232\n0.007880\n0.143081\n0.793169\n0.063750\n0.994274\n0.005726\n[hey, them, it, is, pal, uh, i, was, listening...\n[hey, pal, uh, listening, album, good, lucky, ...\n[hey, pal, uh, listen, album, good, lucky, gue...\n\n\n14\nLose Control\n17phhZDn6oGtzMe56NuWvj\nI've Tried Everything But Therapy (Part 1)\nTeddy Swims\n33qOK5uJ8AR2xuQQAhHump\n2023-09-15\n210688\n87\n81\n[]\n...\n0.000485\n0.000120\n0.557471\n0.412347\n0.030183\n0.998184\n0.001816\n[something, is, got, a, hold, of, me, lately, ...\n[something, got, hold, lately, know, anymore, ...\n[something, get, hold, lately, know, anymore, ...\n\n\n15\nNot Like Us\n6AI3ezQ4o3HUoP6Dhudph3\nNot Like Us\nKendrick Lamar\n2YZyLoL8N0Wb9xBt1NhZWg\n2024-05-04\n274192\n92\n92\n['conscious hip hop', 'hip hop', 'rap', 'west ...\n...\n0.005929\n0.003224\nNaN\nNaN\nNaN\n0.997200\n0.002800\n[psst, i, see, dead, people, mustard, on, the,...\n[psst, see, dead, people, mustard, beat, musta...\n[psst, see, dead, people, mustard, beat, musta...\n\n\n16\nGood Luck, Babe!\n0WbMK4wrZ1wFSty9F7FCgu\nGood Luck, Babe!\nChappell Roan\n7GlBOeep6PqTfFi59PTUUN\n2024-04-05\n218423\n87\n81\n['indie pop', 'pov: indie', 'springfield mo in...\n...\n0.000427\n0.000471\n0.343443\n0.554660\n0.101897\n0.981645\n0.018355\n[it, is, fine, it, is, cool, you, can, say, th...\n[fine, cool, say, nothing, know, truth, guess,...\n[fine, cool, say, nothing, know, truth, guess,...\n\n\n17\nI Can Do It With a Broken Heart\n4q5YezDOIPcoLr8R81x9qy\nTHE TORTURED POETS DEPARTMENT\nTaylor Swift\n06HL4z0CvFAxyc27GXpf02\n2024-04-18\n218004\n84\n100\n['pop']\n...\n0.001501\n0.000734\n0.268903\n0.570628\n0.160469\n0.992031\n0.007969\n[i, can, read, your, mind, she, is, having, th...\n[read, mind, time, life, glittering, prime, li...\n[read, mind, time, life, glitter, prime, light...\n\n\n18\nBelong Together\n5uQ7de4EWjb3rkcFxyEOpu\nBelong Together\nMark Ambor\n11p2E654TTU8e0nZWBR4AL\n2024-02-16\n148317\n87\n75\n['singer-songwriter pop']\n...\n0.005112\n0.002070\n0.018785\n0.284418\n0.696797\n0.206854\n0.793146\n[i, know, sleep, is, friends, with, death, but...\n[know, sleep, friends, death, maybe, get, rest...\n[know, sleep, friend, death, maybe, get, rest,...\n\n\n19\nSaturn\n1bjeWoagtHmUKputLVyDxQ\nSaturn\nSZA\n7tYKF4w9nC0nq9CsPZTHyP\n2024-02-22\n186191\n87\n89\n['pop', 'r&b', 'rap']\n...\n0.077055\n0.002667\n0.401661\n0.494084\n0.104256\n0.998026\n0.001974\n[if, there, is, another, universe, please, mak...\n[another, universe, please, make, noise, noise...\n[another, universe, please, make, noise, noise...\n\n\n20\nSlow It Down\n51eSHglvG1RJXtL3qI5trr\nFireworks & Rollerblades\nBenson Boone\n22wbnEMDvgVIAGdFeek6ET\n2024-04-05\n161831\n85\n85\n['singer-songwriter pop']\n...\n0.669380\n0.007431\n0.709808\n0.263808\n0.026384\n0.983390\n0.016610\n[i, would, never, met, you, but, i, wanted, to...\n[would, never, met, wanted, invite, party, wal...\n[would, never, meet, want, invite, party, walk...\n\n\n21\nAustin\n4NJqhmkGN042BrvHoMKUrJ\nAustin\nDasha\n7Ez6lTtSMjMf2YSYpukP1I\n2023-11-17\n171782\n47\n74\n[]\n...\n0.002042\n0.000548\n0.332335\n0.619888\n0.047777\n0.997655\n0.002345\n[we, had, a, plan, move, out, of, this, town, ...\n[plan, move, town, baby, west, sand, talked, l...\n[plan, move, town, baby, west, sand, talk, lat...\n\n\n22\nStargazing\n3Vr3zh0r7ALn8VLqCiRR10\nStargazing\nMyles Smith\n3bO19AOone0ubCsfDXDtYt\n2024-05-10\n172533\n87\n76\n['singer-songwriter pop']\n...\n0.000203\n0.000153\n0.479969\n0.450779\n0.069251\n0.994339\n0.005661\n[oohooh, oohooh, oohooh, time, stood, still, j...\n[oohooh, oohooh, oohooh, time, stood, still, l...\n[oohooh, oohooh, oohooh, time, stand, still, l...\n\n\n23\nPink Skies\n4ZJ4vzLQekI0WntDbanNC7\nPink Skies\nZach Bryan\n40ZNYROS4zLfyyBSs2PGe2\n2024-05-24\n194920\n84\n88\n['classic oklahoma country']\n...\n0.000670\n0.000719\n0.016503\n0.276442\n0.707055\n0.396575\n0.603425\n[the, kids, are, in, town, for, a, funeral, so...\n[kids, town, funeral, pack, car, dry, eyes, kn...\n[kid, town, funeral, pack, car, dry, eye, know...\n\n\n24\nStick Season\n0mflMxspEfB0VbI1kyLiAv\nStick Season\nNoah Kahan\n2RQXRUsr4IW1f3mKyKsy4B\n2022-10-14\n182346\n86\n84\n['pov: indie']\n...\n0.104740\n0.003200\n0.516024\n0.447031\n0.036945\n0.998780\n0.001220\n[as, you, promised, me, that, i, was, more, th...\n[promised, miles, combined, must, change, hear...\n[promise, mile, combine, must, change, heart, ...\n\n\n25\ngreedy\n3rUGC1vUpkDG9CZFHMur1t\ngreedy\nTate McRae\n45dkTj5sMRSjrmBSBeiHym\n2023-09-15\n131872\n87\n82\n['pop']\n...\n0.001383\n0.000401\n0.257882\n0.650690\n0.091428\n0.970451\n0.029549\n[wood, he, said, are, you, serious, i, have, t...\n[wood, said, serious, tried, figure, next, nig...\n[wood, say, serious, tried, figure, next, nigh...\n\n\n26\nScared To Start\n3Pbp7cUCx4d3OAkZSCoNvn\nScared To Start\nMichael Marcagi\n4j96cMcT8GRi11qbvo1cLQ\n2024-01-12\n159636\n84\n72\n[]\n...\n0.993651\n0.000680\n0.467322\n0.498693\n0.033985\n0.993110\n0.006890\n[she, is, wearing, an, old, dress, walking, it...\n[wearing, old, dress, walking, waiting, someon...\n[wear, old, dress, walk, wait, someone, turn, ...\n\n\n27\nNasty\n6NjWCIYu1W8xa3HIvcIhd4\nNasty\nTinashe\n0NIIxcxNHmOoyBx03SfTCD\n2024-04-12\n176027\n76\n69\n['alternative r&b', 'dance pop', 'metropopolis...\n...\n0.003332\n0.002755\n0.546907\n0.416473\n0.036621\n0.997654\n0.002346\n[because, it, feels, like, heaven, when, it, h...\n[feels, like, heaven, hurts, bad, baby, put, l...\n[feel, like, heaven, hurt, bad, baby, put, lik...\n\n\n28\nWater\n5aIVCx5tnk0ntmdiinnYvw\nWater\nTyla\n3SozjO3Lat463tQICI9LcE\n2023-07-28\n200255\n83\n77\n[]\n...\n0.006878\n0.002168\n0.210546\n0.642083\n0.147372\n0.992614\n0.007386\n[make, me, sweat, make, me, hotter, make, me, ...\n[make, sweat, make, hotter, make, lose, breath...\n[make, sweat, make, hotter, make, lose, breath...\n\n\n29\nGata Only\n6XjDF6nds4DE2BBbagZol6\nGata Only\nFloyyMenor\n7CvTknweLr9feJtRGrpDBy\n2024-02-02\n222000\n92\n80\n['reggaeton chileno']\n...\n0.889733\n0.003425\n0.223531\n0.686388\n0.090082\n0.995981\n0.004019\n[hey, mommy, i, feel, you, far, away, tell, me...\n[hey, mommy, feel, far, away, tell, want, goin...\n[hey, mommy, feel, far, away, tell, want, go, ...\n\n\n30\nMiles On It\n4pkb8SbRGeHAvdb87v9rpf\nMiles On It\nMarshmello\n64KEffDW9EtZ1y2vBYgq8T\n2024-05-03\n168355\n79\n82\n['brostep', 'edm', 'pop', 'progressive electro...\n...\n0.022199\n0.003526\n0.144933\n0.754521\n0.100546\n0.997120\n0.002880\n[new, truck, big, lift, old, roads, we, have, ...\n[new, truck, big, lift, old, roads, tearing, s...\n[new, truck, big, lift, old, road, tear, since...\n\n\n31\nyes, and?\n7gaA3wERFkFkgivjwbSvkG\nyes, and?\nAriana Grande\n66CXWjxzNUsdJxJ2JdwvnR\n2024-01-12\n214994\n77\n90\n['pop']\n...\n0.001213\n0.000830\n0.136892\n0.807006\n0.056103\n0.868278\n0.131722\n[in, case, you, have, not, noticed, well, ever...\n[case, noticed, well, everybodys, tired, heali...\n[case, notice, well, everybodys, tire, heal, s...\n\n\n32\nTEXAS HOLD 'EM\n0Z7nGFVCLfixWctgePsRk9\nTEXAS HOLD 'EM\nBeyoncé\n6vWDO969PvNqNYHIOW5v0m\n2024-02-11\n233456\n81\n86\n['pop', 'r&b']\n...\n0.095105\n0.005935\n0.063050\n0.677763\n0.259187\n0.991808\n0.008192\n[this, are, not, texts, wood, are, not, no, ho...\n[texts, wood, hold, lay, cards, park, nexus, w...\n[texts, wood, hold, lay, card, park, nexus, wo...\n\n\n33\nBAND4BAND (feat. Lil Baby)\n7iabz12vAuVQYyekFIWJxD\nBAND4BAND (feat. Lil Baby)\nCentral Cee\n5H4yInM5zmHqpKIoMNAx4r\n2024-05-23\n140733\n86\n80\n['melodic drill', 'r&drill']\n...\n0.031337\n0.003643\n0.158056\n0.726879\n0.115065\n0.995000\n0.005000\n[i, am, not, in, the, mood, because, my, fligh...\n[mood, flight, delayed, jumped, private, jet, ...\n[mood, flight, delay, jump, private, jet, ask,...\n\n\n34\nFeel It - From The Original Series “Invincible”\n3SAga35lAPYdjj3qyfEsCF\nFeel It (From The Original Series “Invincible”)\nd4vd\n5y8tKLUfMvliMe8IKamR32\n2024-03-28\n157974\n81\n77\n['bedroom pop']\n...\n0.052882\n0.003317\n0.217128\n0.640834\n0.142039\n0.968726\n0.031274\n[what, do, you, have, in, store, one, life, aw...\n[store, one, life, away, explore, want, get, w...\n[store, one, life, away, explore, want, get, w...\n\n\n35\nOne Of The Girls (with JENNIE, Lily Rose Depp)\n7CyPwkp0oE8Ro9Dd5CUDjW\nThe Idol Episode 4 (Music from the HBO Origina...\nThe Weeknd\n1Xyo4u8uXC1ZmMpatF05PJ\n2023-06-23\n244684\n87\n92\n['canadian contemporary r&b', 'canadian pop', ...\n...\n0.018034\n0.003468\n0.178038\n0.707149\n0.114813\n0.885132\n0.114868\n[lock, me, up, and, throw, away, the, key, he,...\n[lock, throw, away, key, knows, get, best, for...\n[lock, throw, away, key, know, get, best, forc...\n\n\n36\nTell Ur Girlfriend\n3lMzT16MjAKKXF7pSZn13B\nTell Ur Girlfriend\nLay Bankz\n4OVbrPbhvK46A1uXTU1u5F\n2024-02-07\n124444\n83\n72\n['jersey club']\n...\n0.193861\n0.006144\n0.154598\n0.793314\n0.052088\n0.989258\n0.010742\n[should, tell, my, boyfriend, what, i, been, d...\n[tell, boyfriend, thinking, every, time, want,...\n[tell, boyfriend, think, every, time, want, ge...\n\n\n37\nLovin On Me\n4xhsWYTOGcal8zt0J161CU\nLovin On Me\nJack Harlow\n2LIk90788K0zvyj2JJVwkJ\n2023-11-10\n138411\n83\n79\n['deep underground hip hop', 'kentucky hip hop...\n...\n0.001004\n0.001236\n0.150591\n0.733557\n0.115853\n0.941148\n0.058852\n[i, do, not, like, no, whips, and, chains, and...\n[like, whips, chains, tie, whip, loving, baby,...\n[like, whip, chain, tie, whip, love, baby, whi...\n\n\n38\nSanta\n5bi0gh89wRuH2OgjdAKFsb\nSanta\nRvssian\n1fctva4kpRbg2k3v7kwRuS\n2024-04-04\n193038\n85\n75\n['reggaeton', 'reggaeton flow', 'trap latino',...\n...\n0.222502\n0.006456\n0.260976\n0.676515\n0.062509\n0.986034\n0.013966\n[they, rvssian, i, can, not, deny, this, desir...\n[rvssian, deny, desire, stop, looking, lips, r...\n[rvssian, deny, desire, stop, look, lip, rejec...\n\n\n39\nCHIHIRO\n7BRD7x5pt8Lqa1eGYC4dzj\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n303440\n90\n94\n['art pop', 'pop']\n...\n0.088560\n0.007637\n0.350795\n0.600648\n0.048556\n0.992751\n0.007249\n[to, take, my, love, away, when, i, come, back...\n[take, love, away, come, back, around, know, s...\n[take, love, away, come, back, around, know, s...\n\n\n40\nWhatever\n0LMwmV37RCmBO2so0szAFs\nWhatever\nKygo\n23fqKkggKUBHNkbKtXEls4\n2024-01-19\n178273\n83\n79\n['edm', 'pop', 'pop dance', 'tropical house']\n...\n0.004015\n0.002350\n0.610942\n0.347206\n0.041852\n0.994950\n0.005050\n[there, is, a, space, in, my, heart, when, it,...\n[space, heart, comes, crashing, anytime, hear,...\n[space, heart, come, crash, anytime, hear, nam...\n\n\n41\nIllusion\n59xD5osEFsaNt5PXfIKUnX\nIllusion\nDua Lipa\n6M2wZ9GZgrQXHCFfjv46we\n2024-04-11\n188143\n78\n87\n['dance pop', 'pop', 'uk pop']\n...\n0.292987\n0.295016\n0.178378\n0.761315\n0.060307\n0.980528\n0.019472\n[i, been, known, to, miss, a, red, flag, i, be...\n[known, miss, red, flag, known, put, lover, pe...\n[know, miss, red, flag, know, put, lover, pede...\n\n\n42\nI Don't Wanna Wait\n331l3xABO0HMr1Kkyh2LZq\nI Don't Wanna Wait\nDavid Guetta\n1Cs0zKBU1kc0i8ypK3B9ai\n2024-04-05\n149667\n84\n87\n['big room', 'dance pop', 'edm', 'pop', 'pop d...\n...\n0.000750\n0.001233\n0.186699\n0.667073\n0.146227\n0.926766\n0.073234\n[let, us, make, tonight, the, weekend, i, do, ...\n[let, us, make, tonight, weekend, want, waiait...\n[let, u, make, tonight, weekend, want, waiait,...\n\n\n43\nJump\n0ve0CavjqrUqVmZ605RhTV\nJump\nTyla\n3SozjO3Lat463tQICI9LcE\n2024-03-20\n147071\n74\n77\n[]\n...\n0.074129\n0.006129\n0.160605\n0.730697\n0.108697\n0.992549\n0.007451\n[original, goal, you, are, no, replica, not, s...\n[original, goal, replica, smooth, dean, regula...\n[original, goal, replica, smooth, dean, regula...\n\n\n44\nI Remember Everything (feat. Kacey Musgraves)\n4KULAymBBJcPRpk1yO4dOG\nZach Bryan\nZach Bryan\n40ZNYROS4zLfyyBSs2PGe2\n2023-08-25\n227195\n84\n88\n['classic oklahoma country']\n...\n0.061445\n0.007630\nNaN\nNaN\nNaN\n0.986801\n0.013199\n[each, bran, i, remember, everything, feat, pa...\n[bran, remember, everything, feat, pacey, musg...\n[bran, remember, everything, feat, pacey, musg...\n\n\n45\none of wun\n4Na2HfNSr58chvfX69fy36\nOne of Wun\nGunna\n2hlmm7s2ICUX0LVIhVFlZQ\n2024-05-10\n144000\n82\n86\n['atl hip hop', 'melodic rap', 'rap', 'trap']\n...\n0.047478\n0.007180\n0.224431\n0.700020\n0.075549\n0.991757\n0.008243\n[that, is, a, good, one, pa, someone, they, te...\n[good, one, pa, someone, tens, one, one, never...\n[good, one, pa, someone, tens, one, one, never...\n\n\n46\nobsessed\n6tNgRQ0K2NYZ0Rb9l9DzL8\nGUTS (spilled)\nOlivia Rodrigo\n1McMsnEElThX1knmY4oliG\n2024-03-22\n170541\n80\n87\n['pop']\n...\n0.002200\n0.000302\n0.324626\n0.581667\n0.093707\n0.993318\n0.006682\n[law, dada, data, lambda, law, dada, dada, if,...\n[law, dada, data, lambda, law, dada, dada, tol...\n[law, dada, data, lambda, law, dada, dada, tol...\n\n\n47\nMagnetic\n1aKvZDoLGkNMxoRYgkckZG\nSUPER REAL ME\nILLIT\n36cgvBn0aadzOijnjjwqMN\n2024-03-25\n160688\n86\n74\n['5th gen k-pop']\n...\n0.069957\n0.007273\n0.092965\n0.713226\n0.193809\n0.986112\n0.013888\n[baby, i, am, just, trying, to, play, it, cool...\n[baby, trying, play, cool, hide, want, wait, m...\n[baby, try, play, cool, hide, want, wait, minu...\n\n\n48\nredrum\n52eIcoLUM25zbQupAZYoFh\namerican dream\n21 Savage\n1URnnhqYAYcrqrcwql10ft\n2024-01-12\n270697\n84\n88\n['atl hip hop', 'hip hop', 'rap']\n...\n0.096404\n0.007055\n0.236659\n0.726418\n0.036923\n0.995288\n0.004712\n[cain, a, note, sore, o, boss, armor, cain, e,...\n[cain, note, sore, boss, armor, cain, e, agora...\n[cain, note, sore, bos, armor, cain, e, agora,...\n\n\n\n\n49 rows × 39 columns",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "02_genre_classification/01_classification_model.html",
    "href": "02_genre_classification/01_classification_model.html",
    "title": "Genre Classification Model",
    "section": "",
    "text": "Objective. Construct a classification model that can accurately predict the genre of a song using a dataset containing Spotify track information, including artist details and genres. The model will utilize the audio features and potentially the lyrics of each track to make its predictions. Additionally, it will be trained using the artist genre list as well as a separate dataset of tracks that have been labeled with their respective genres.\nConstructing a classification model to predict the genre of a song involves several steps, including data preprocessing, feature engineering, model selection, training, and evaluation. Here’s a step-by-step guide to achieve this:\n\ngenres_v2['genre'].value_counts()\n\nacoustic    110\npop         109\nemo         108\nhappy       108\nsad         107\npunk        107\nromance     106\ngrunge      106\nhip-hop     105\nchill       105\ndance       103\npiano       103\nindie       102\nrock        101\nedm          77\ntechno       59\nr-n-b        58\nName: genre, dtype: int64\n\n\n\nStep 1: Data Collection\nGather the necessary datasets: - Spotify API: Use the Spotify API to collect track information, including audio features (e.g., danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo). - Artist Genre Data: Gather genres associated with each artist from Spotify’s API. - Lyrics Data: Includes the lyrics of the tracks (optional but can enhance the model’s performance). - Genre Labels: Obtain a labeled dataset of tracks with their respective genres for training.\nWe want to try and predict a song’s genre based off of these audio features. Spotify provides a “genre seed:” an array of genres associated with the song used for the recommendation function of the API. We use the API to search for the top 1000 songs in a given genre, pull the audio features for each song, and add on the genre label.\n\n\n\n\n\n\n\n\n\n\npopularity\nacousticness\ndanceability\nenergy\ninstrumentalness\nliveness\nloudness\nspeechiness\ntempo\nvalence\nkey\nmode\ntime_signature\n\n\n\n\ncount\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n1674.000000\n\n\nmean\n27.680406\n0.228153\n0.557579\n0.654587\n0.113044\n0.188549\n-7.521858\n0.079652\n122.751480\n0.441805\n5.263441\n0.648148\n3.931302\n\n\nstd\n27.194546\n0.312398\n0.167096\n0.244701\n0.263844\n0.152054\n4.460943\n0.081385\n28.238078\n0.232465\n3.607028\n0.477691\n0.381192\n\n\nmin\n0.000000\n0.000002\n0.062100\n0.001500\n0.000000\n0.021500\n-41.446000\n0.022600\n42.646000\n0.027500\n0.000000\n0.000000\n1.000000\n\n\n25%\n0.000000\n0.005390\n0.444000\n0.489000\n0.000000\n0.095725\n-9.013000\n0.035425\n100.149750\n0.256250\n2.000000\n0.000000\n4.000000\n\n\n50%\n26.000000\n0.056100\n0.555000\n0.707500\n0.000046\n0.126000\n-6.326000\n0.048200\n123.467500\n0.417000\n6.000000\n1.000000\n4.000000\n\n\n75%\n53.000000\n0.357750\n0.676000\n0.855000\n0.012950\n0.230750\n-4.653750\n0.084075\n140.063750\n0.613750\n8.000000\n1.000000\n4.000000\n\n\nmax\n83.000000\n0.995000\n0.969000\n0.996000\n0.978000\n0.988000\n-1.264000\n0.578000\n214.008000\n0.980000\n11.000000\n1.000000\n5.000000\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Data Preprocessing\nClean and preprocess the data to prepare it for model training. - Handle Missing Values: Remove or impute missing data. - Normalize/Standardize Features: Normalize or standardize the audio features to ensure they are on a similar scale. - Text Preprocessing for Lyrics: Tokenize, remove stopwords, and potentially use techniques like TF-IDF or word embeddings for the lyrics.\n\n# Normalize audio features\nfrom sklearn.preprocessing import StandardScaler\n\n# Define audio features\naudio_features = ['danceability', 'energy', 'key', 'loudness', 'speechiness', 'acousticness',\n                  'instrumentalness', 'liveness', 'valence', 'tempo']\n\n# Fit and transform audio features\nscaler = StandardScaler()\ndf[audio_features] = scaler.fit_transform(df[audio_features])\n\n\n\n\nStep 3. Feature Engineering\nCreate features from the available data. - Audio Features: Use the provided audio features. - Artist Genre Encoding: Encode categorical features (i.e. genres) using one-hot encoding or other suitable methods. - Lyrics Features: Convert lyrics into numerical features using techniques like TF-IDF, Word2Vec, or BERT embeddings. - Extract additional features from lyrics (e.g., sentiment analysis, topic modeling).\n\nLabel Encoder\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()  # Encode the target variable\ndf['genre_encoded'] = le.fit_transform(df['genre'])\n\nCombine and arrange the data to create a final dataset for training the model.\n\nX = df[['danceability', 'energy', 'key', 'loudness', 'speechiness',\n        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\ny = df[['genre_encoded']]\n\n\n\n\n\nStep 4: Model Selection and Training\nChoose an appropriate classification algorithm and train the model. - Algorithms: Consider using algorithms like Random Forest, Gradient Boosting, Support Vector Machine (SVM), or Neural Networks. - Cross-Validation: Use cross-validation to tune hyperparameters and avoid overfitting.\n\nModel Training\nThe following code divides a dataset into training and testing subsets. It divides the input variables and target variables into 80% training and 20% testing groups at random. The descriptive statistics of the training data are then outputted to aid in data exploration and the identification of possible problems.\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # test_size=0.2\n\n\n\nModel Fitting\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nfrom prettytable import PrettyTable\n\n\n# Define models\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=0.5, random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=5, random_state=42),\n    \"SVM\": SVC(probability=True, random_state=42),\n    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n    \"Decision Tree\": DecisionTreeClassifier(max_depth=7, min_samples_split=5, random_state=42),\n    \"Gradient Boost\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, random_state=42),\n    \"XGB\": XGBClassifier(n_estimators=300, random_state=42)\n}\n\n\n\n\n\nStep 6: Model Evaluation\nEvaluate the model’s performance using appropriate metrics. - Metrics: Use accuracy, precision, recall, F1-score, and confusion matrix to assess the model. - Validation Set: Use a separate validation set to test the model’s generalization ability.\nWe can evaluate the performance of different models using multiple criteria: Accuracy, ROC-AUC, Precision, Recall, and F1-Score. Based on the provided metrics, let’s analyze the performance of each model to determine which one is the best:\n\n# Initialize an empty list to store the results\nresults = []\n\n# Train models and evaluate\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n\n    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n\n    results.append({\n        \"Model\": name, \n        \"Accuracy\": accuracy_score(y_test, y_pred), \n        \"ROC-AUC\": roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else None,\n        \"Precision\": report['weighted avg']['precision'], \n        \"Recall\": report['weighted avg']['recall'], \n        \"F1-Score\": report['weighted avg']['f1-score']\n    })\n\n\n\n\n\n\n\n\n\n \nModel\nAccuracy\nROC-AUC\nPrecision\nRecall\nF1-Score\n\n\n\n\n0\nLogistic Regression\n0.291169\n0.812339\n0.286944\n0.291169\n0.272028\n\n\n1\nRandom Forest\n0.329356\n0.832776\n0.335009\n0.329356\n0.305644\n\n\n2\nSVM\n0.298329\n0.816533\n0.287245\n0.298329\n0.278114\n\n\n3\nNeural Network\n0.288783\n0.803341\n0.282435\n0.288783\n0.281682\n\n\n4\nKNN\n0.233890\n0.669295\n0.226509\n0.233890\n0.222153\n\n\n5\nDecision Tree\n0.272076\n0.739925\n0.271790\n0.272076\n0.250733\n\n\n6\nGradient Boost\n0.315036\n0.814781\n0.328956\n0.315036\n0.313637\n\n\n7\nXGB\n0.286396\n0.781179\n0.289853\n0.286396\n0.285033\n\n\n\n\n\n\n\nConclusion\nConsidering all metrics, Random Forest appears to be the best model overall due to its high performance across multiple metrics (accuracy and ROC-AUC), while the Neural Network also performs well with the highest precision and F1-Score.\nThese results suggest that the Random Forest, Neural Network, and SVM models are the most effective for this specific task of predicting the genre of a song using the given dataset.\n\n\n\n\n\nStep 7: Model Deployment\nDeploy the model for practical use. - Save the Model: Save the trained model using libraries like joblib or pickle. - API Creation: Create an API using Flask or FastAPI to make predictions on new data.\n\nimport joblib\n\n# Train the Random Forest model\nrandom_forest_model = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=5, random_state=42)\nrandom_forest_model.fit(X_train, y_train)\n\n# Save scaler + model for future use\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(random_forest_model, 'random_forest_model.pkl')\n\n['random_forest_model.pkl']\n\n\n\n# Evaluate the model\ny_pred = random_forest_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\nAccuracy: 0.32935560859188545\n\n\n\nApplying Model to New Data\n\n# Load the trained models + scaler\nrandom_forest_model = joblib.load('random_forest_model.pkl')\nscaler = joblib.load('scaler.pkl')\n\n\n# Load new data\ndf_new = pd.read_csv(\"../assets/data/all_tracks+lyrics.csv\")\n\n# Extract relevant columns\nnew_data = df_new[['name', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n                   'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n\n# Preprocess new data\nX_new_data = new_data.drop(columns=['name'])\nX_new_data_scaled = scaler.transform(X_new_data)\n\n\n# Make predictions\npredictions = random_forest_model.predict(X_new_data_scaled)\nprobabilities = random_forest_model.predict_proba(X_new_data_scaled)\n\n# Decode the predicted genre labels\npredictions_label = le.inverse_transform(predictions)\n\n# Display predictions\nnew_data['Predicted Genre'] = predictions\nnew_data['Predicted Genre Label'] = predictions_label\nnew_data['Prediction Probabilities'] = probabilities.tolist()\n\nnew_data[['name', 'Predicted Genre Label', 'Predicted Genre', 'Prediction Probabilities']]\n\n\n\n\n\n\n\n\n\nname\nPredicted Genre Label\nPredicted Genre\nPrediction Probabilities\n\n\n\n\n0\nEspresso\npop\n10\n[0.04832254153187096, 0.12619269101055017, 0.0...\n\n\n1\nBIRDS OF A FEATHER\nindie\n8\n[0.062251132860993375, 0.1350221101568469, 0.1...\n\n\n2\nI Had Some Help (Feat. Morgan Wallen)\nhappy\n6\n[0.029337791261863377, 0.07129928471933508, 0....\n\n\n3\nToo Sweet\nhappy\n6\n[0.03110784942385244, 0.07207603026340323, 0.1...\n\n\n4\nMILLION DOLLAR BABY\npop\n10\n[0.021188299219084113, 0.06175288340078473, 0....\n\n\n5\nwe can't be friends (wait for your love)\npop\n10\n[0.06131610996839342, 0.09285144407448995, 0.0...\n\n\n6\nA Bar Song (Tipsy)\npop\n10\n[0.06472761794832327, 0.1272680424393216, 0.02...\n\n\n7\nLUNCH\ndance\n2\n[0.057410671030815943, 0.07659489738600524, 0....\n\n\n8\nFortnight (feat. Post Malone)\nsad\n15\n[0.1634002656168661, 0.13524188930269576, 0.00...\n\n\n9\nBeautiful Things\nromance\n14\n[0.06134736364973052, 0.08543240103706232, 0.0...\n\n\n10\ni like the way you kiss me\nrock\n13\n[0.007352859917424355, 0.0186163664804808, 0.1...\n\n\n11\nPlease Please Please\npop\n10\n[0.05484400855863455, 0.09565418558487603, 0.0...\n\n\n12\nEnd of Beginning\ndance\n2\n[0.09961923753210948, 0.0904829832820782, 0.11...\n\n\n13\nHoudini\nhappy\n6\n[0.010771952741578305, 0.07198130147963207, 0....\n\n\n14\nLose Control\nromance\n14\n[0.053126154256947646, 0.12564655171183095, 0....\n\n\n15\nNot Like Us\nhip-hop\n7\n[0.031892615385277774, 0.07170660657451432, 0....\n\n\n16\nGood Luck, Babe!\npop\n10\n[0.07813084208166093, 0.09704788505899932, 0.0...\n\n\n17\nI Can Do It With a Broken Heart\npop\n10\n[0.04922753425420418, 0.08735245470843163, 0.0...\n\n\n18\nBelong Together\npop\n10\n[0.11179875786263554, 0.12087464660186649, 0.0...\n\n\n19\nSaturn\nacoustic\n0\n[0.14686346634076933, 0.10380959997550107, 0.0...\n\n\n20\nSlow It Down\nhappy\n6\n[0.05372462763732637, 0.07412152089580584, 0.0...\n\n\n21\nAustin\npop\n10\n[0.0501664673717607, 0.0933994660596392, 0.052...\n\n\n22\nStargazing\npop\n10\n[0.0700828327026069, 0.1180781676318351, 0.036...\n\n\n23\nPink Skies\nchill\n1\n[0.09012108560090301, 0.15018375147564447, 0.0...\n\n\n24\nStick Season\nacoustic\n0\n[0.18591473045968132, 0.08382765471124884, 0.0...\n\n\n25\ngreedy\nhappy\n6\n[0.06177391429539499, 0.0887022100914361, 0.02...\n\n\n26\nScared To Start\nchill\n1\n[0.13107766291528747, 0.14041067548070166, 0.0...\n\n\n27\nNasty\nhip-hop\n7\n[0.05112198969699953, 0.09815715992186375, 0.0...\n\n\n28\nWater\npop\n10\n[0.036958899774743065, 0.09166638627468936, 0....\n\n\n29\nGata Only\nhip-hop\n7\n[0.07944251331085496, 0.10507118676058398, 0.0...\n\n\n30\nMiles On It\nhappy\n6\n[0.030293084752480434, 0.060393964528687914, 0...\n\n\n31\nyes, and?\npop\n10\n[0.03923640328030741, 0.10172945800400378, 0.0...\n\n\n32\nTEXAS HOLD 'EM\npop\n10\n[0.06947162655502154, 0.09576348368506085, 0.0...\n\n\n33\nBAND4BAND (feat. Lil Baby)\nhip-hop\n7\n[0.010963028586862973, 0.07859730857102712, 0....\n\n\n34\nFeel It - From The Original Series “Invincible”\npop\n10\n[0.04719639945364053, 0.07947306411719812, 0.0...\n\n\n35\nOne Of The Girls (with JENNIE, Lily Rose Depp)\nromance\n14\n[0.04780153582857584, 0.08538916614307925, 0.0...\n\n\n36\nTell Ur Girlfriend\nhip-hop\n7\n[0.005698984522066412, 0.04019258793156138, 0....\n\n\n37\nLovin On Me\nhappy\n6\n[0.0239466418597217, 0.07187688521272997, 0.07...\n\n\n38\nSanta\npop\n10\n[0.036950640543466605, 0.09902254261629856, 0....\n\n\n39\nCHIHIRO\npiano\n9\n[0.06865514957748471, 0.08885887995987213, 0.1...\n\n\n40\nWhatever\npop\n10\n[0.04481988407189988, 0.09728907499399733, 0.0...\n\n\n41\nIllusion\npop\n10\n[0.03406716211351513, 0.08771688922697399, 0.0...\n\n\n42\nI Don't Wanna Wait\npop\n10\n[0.04502505120855936, 0.09875116742062903, 0.0...\n\n\n43\nJump\npop\n10\n[0.02580044873861146, 0.10764863778519679, 0.0...\n\n\n44\nI Remember Everything (feat. Kacey Musgraves)\nacoustic\n0\n[0.18922332829839963, 0.12607182575835746, 0.0...\n\n\n45\none of wun\nhip-hop\n7\n[0.003697849395802203, 0.04443929940707556, 0....\n\n\n46\nobsessed\npop\n10\n[0.039187875030013225, 0.09090484970317311, 0....\n\n\n47\nMagnetic\npop\n10\n[0.03485985300807636, 0.07644729855332005, 0.0...\n\n\n48\nredrum\ndance\n2\n[0.03290810189070711, 0.06273202050019706, 0.1...",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Genre Classification Model</span>"
    ]
  }
]