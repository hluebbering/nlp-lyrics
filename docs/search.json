[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NLP Song Lyrics",
    "section": "",
    "text": "Overview\nObjective. The following project involves extracting and analyzing Spotify data from top playlists using the Spotify and Genius Lyrics Web API. Natural Language Processing techniques are used to process lyrics and perform sentiment analysis. K-means clustering and PCA analysis are employed to categorize songs and analyze relationships between musical features.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#extracting-spotify-data",
    "href": "index.html#extracting-spotify-data",
    "title": "NLP Song Lyrics",
    "section": "Extracting Spotify Data",
    "text": "Extracting Spotify Data\nGetting started, we want to extract data for a set of tracks within one of Spotify’s top-featured playlists. Leveraging the Spotify Web API, we can seamlessly obtain detailed data for a song, such as the artist, the album it belongs to, its release date, popularity, and audio features like danceability, energy, and tempo.\n\nAccessing the Spotify Web API\nPython libraries like spotipy offer a user-friendly way to interact with the Spotify API, offering a range of functions that streamline tasks like API authentication. To authenticate access, we provide a client ID and secret. Once authenticated, we can interact with the API and retrieve data.\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\nmy_auth = SpotifyClientCredentials(client_id = \"xxx\", client_secret = \"xxx\")\nsp = spotipy.Spotify(auth_manager=my_auth)  # Spotify authentication\n\n\nSpotify’s Featured Playlists\nLet’s take a look at the popular Spotify playlists. Below, the code retrieves a range of Spotify playlists and generates a dataframe containing details for each playlist.\n\n\n\n\n\n\n\nthumbnail\nplaylist_name\nplaylist_id\ndescription\ntotal\n\n\n\n\n0\n\nToday’s Top Hits\n37i9dQZF1DXcBWIGoYBM5M\nKarol G is on top of the Hottest 50!\n50\n\n\n1\n\nRapCaviar\n37i9dQZF1DX0XUsuxWHRQd\nNew music from Eminem, Ice Spice and BossMan DLow.\n50\n\n\n2\n\nHot Country\n37i9dQZF1DX1lVhptIYRda\nToday's top country hits. Cover: Megan Moroney\n50\n\n\n\n\n\n\n\n\n\n\nExtracting Track Data From Playlist\nNext, we utilize Spotify’s API to extract further details about each song within the playlist. We obtain metadata such as the track name, the artist it’s sung by, the album it belongs to, the release date, and track features such as danceability, tempo, and popularity.\n\ndef get_playlist_tracks(playlist_URI):\n    results = sp.playlist_tracks(playlist_URI)\n    tracks = results[\"items\"]\n    while results[\"next\"]:\n        results = sp.next(results)\n        tracks.extend(results[\"items\"])\n    return tracks\n\nChoose a specific playlist to analyze by copying the URL from the Spotify Player interface. Using that link, the playlist_tracks method retrieves a list of IDs and corresponding artists for each track from the playlist. Specifically, we analyze Spotify’s Today’s Top Hits playlist.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#natural-language-processing",
    "href": "index.html#natural-language-processing",
    "title": "NLP Song Lyrics",
    "section": "Natural Language Processing",
    "text": "Natural Language Processing\nUsing the data gathered from the Spotify API, we now want to extract and process lyrics for each song. This is accomplished through scraping textual lyrical data from the Genius Lyrics website. Following extraction, the lyrics are cleaned before undergoing sentiment analysis.\n\nScraping Song Lyrics\nThe lyricsgenius is a fundamental library allowing for web scraping of the Genius Lyrics website. Through the initialization of the genius variable, one can access the Genius API and retrieve the lyrics of any given song, such as “Too Many Nights” by Metro Boomin.\n\nimport lyricsgenius\ngenius = lyricsgenius.Genius(access_token) # Initialize Genius API\nsong = genius.search_song(\"Too Many Nights\", \"Metro Boomin\")\n\nSearching for \"Too Many Nights\" by Metro Boomin...\nDone.\n\n\n\n\nPre-Processing Text Data\nUsing the genius library, we define a function to fetch the lyrics of a song given the name and artist. Once retrieved, the next step is to pre-process the lyrics. This involves a cleaning process to eliminate patterns that may hinder the overall readability. The script contains the following steps:\n\n\nFetching Track Lyrics\nExpanding Contractions\nConverting Text to Lowercase\nSpell Checking + Censoring\nRemoving Punctuations\nTokenizing and encoding to ASCII\n\n\n\n\ndef clean_song_lyrics(song_name, artist_name):\n    # Fetch song lyrics and clean\n    lyrics = get_song_lyrics(song_name, artist_name) \n    lyrics = profanity.censor(contractions.fix(lyrics).lower(), censor_char=\"\")\n    lyrics = remove_punctuation(lyrics) \n    \n    # Tokenizing and encoding to ASCII\n    return [word.encode(\"ascii\", \"ignore\").decode() for word in word_tokenize(lyrics)]\n\n\nFurther Text Cleaning\nWe employ the Natural Language Toolkit (NLTK) to filter out stopwords and perform lemmatization. Removing common words like “the” condenses the text, allowing for a more thorough analysis of the lyrics’ core message. Lemmatization helps standardize text by transforming different verb variations into their most basic form.\n\n\n\n\n\n\n\n\n\n\nname\nartist\nlyrics\nstopwords_removed\nlemmatized\n\n\n\n\n0\nPlease Please Please\nSabrina Carpenter\n['i', 'know', 'i', 'have', 'good', 'judgment', 'i',...\n['know', 'good', 'judgment', 'know', 'good', 'taste...\n['know', 'good', 'judgment', 'know', 'good', 'taste...\n\n\n1\nSi Antes Te Hubiera Conocido\nKAROL G\n['what', 'what', 'we', 'are', 'in', 'a', 'relay', '...\n['relay', 'summer', 'started', 'fire', 'would', 'me...\n['relay', 'summer', 'start', 'fire', 'would', 'meet...\n\n\n2\nBIRDS OF A FEATHER\nBillie Eilish\n['i', 'want', 'you', 'to', 'stay', 'til', 'i', 'am'...\n['want', 'stay', 'til', 'grave', 'til', 'rot', 'awa...\n['want', 'stay', 'til', 'grave', 'til', 'rot', 'awa...\n\n\n\n\n\n\n\n\n\n\nTerm Frequency Analysis\n\nLet’s examine the most frequent words. Plotting the frequency distribution helps to determine the occurrence of the most common terms in our lyrical corpus.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#sentiment-analysis",
    "href": "index.html#sentiment-analysis",
    "title": "NLP Song Lyrics",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nThe next process involves implementing pipelines to predict emotions and sentiment in textual content using transformer models designed for text classification and sentiment analysis. Three distinct pipelines are created, each equipped with different models.\n\nfrom transformers import pipeline\n\nclassifiers = [ # Initialize sentiment classifiers\n    pipeline(model='bhadresh-savani/distilbert-base-uncased-emotion'),\n    pipeline(model='cardiffnlp/twitter-roberta-base-sentiment')\n]\n\nOne of the classifiers is the distilbert-base-uncased-emotion model, which detects emotions in texts like sadness, joy, love, anger, fear, and surprise. Another classifier is the roBERTa-base model “trained on 58 million tweets and fine-tuned for sentiment analysis using the TweetEval benchmark” (EMNLP 2020).\nWe then implement the get_lyric_sentiment function, which uses three classifiers to calculate sentiment scores from pre-processed lyrics.\n\n# Function to perform sentiment analysis\ndef get_lyric_sentiment(lyrics, classifiers):\n    text = \" \".join(lyrics)\n    scores = {}\n    for classifier in classifiers:\n        try:\n            predictions = classifier(text, truncation=True)\n            for prediction in predictions[0]:\n                scores[prediction[\"label\"]] = prediction[\"score\"]\n        except Exception as e:\n            print(f\"Error during sentiment analysis: {e}\")\n    return scores\n\nBelow is a graphical representation of the results obtained from the roBERTa-base model. According to the TweetEval reference paper and official Github repository, the resulting labels 0, 1, and 2 correspond to Negative, Neutral, and Positive, respectively.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#putting-it-all-together",
    "href": "index.html#putting-it-all-together",
    "title": "NLP Song Lyrics",
    "section": "Putting it All Together",
    "text": "Putting it All Together\nTo summarize, the code efficiently collects data and performs text analysis on every song in a playlist. Specifically, it systematically processes a list of tracks and corresponding artists while simultaneously conducting a thorough cleaning procedure on the lyrics. Additionally, the program computes a sentiment score for each song based on the lyrics, indicating whether the lyrics are positive, negative, or neutral.\n\n\n\n\n\n\n\n\n\n\nname\nalbum\nartist\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\nacousticness\ndanceability\n...\njoy\nlove\nanger\nfear\nsurprise\nLABEL_0\nLABEL_1\nLABEL_2\nNEGATIVE\nPOSITIVE\n\n\n\n\n0\nPlease Please Please\nPlease Please Please\nSabrina Carpenter\n2024-06-06\n186365\n98\n91\n['pop']\n0.274\n0.669\n...\n0.955393\n0.035888\n0.002778\n0.000637\n0.000841\n0.251058\n0.542962\n0.205980\n0.857851\n0.142149\n\n\n1\nSi Antes Te Hubiera Conocido\nSi Antes Te Hubiera Conocido\nKAROL G\n2024-06-21\n195824\n91\n89\n['reggaeton', 'reggaeton colombiano', 'trap latino'...\n0.446\n0.924\n...\n0.003352\n0.008062\n0.982214\n0.002481\n0.000541\n0.043676\n0.469266\n0.487059\n0.957238\n0.042762\n\n\n2\nBIRDS OF A FEATHER\nHIT ME HARD AND SOFT\nBillie Eilish\n2024-05-17\n210373\n98\n94\n['art pop', 'pop']\n0.200\n0.747\n...\n0.180090\n0.008181\n0.068175\n0.434426\n0.034063\n0.122799\n0.504202\n0.372999\n0.959893\n0.040107\n\n\n\n\n3 rows × 33 columns\n\n\n\n\nIn summary, the above code aims to collect and refine song lyrics by eliminating stopwords and conducting lemmatization. Subsequently, it employs pre-trained models for sentiment analysis to determine the prevailing emotion conveyed in the lyrics. Finally, the program compiles all this information into a dataframe for further analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#correlations-matrix",
    "href": "index.html#correlations-matrix",
    "title": "NLP Song Lyrics",
    "section": "Correlations Matrix",
    "text": "Correlations Matrix\nAfter completing the initial data analysis, we proceed with generating the Pearson correlations matrix using the Pandas command df.corr(). Subsequently, we visualize the matrix using the seaborn heatmap, providing a detailed understanding of the relationships between the various variables in our dataset.\n\ntrack_sentiment_df = df_final[['name', 'artist',\n           'acousticness', 'danceability', 'energy', 'instrumentalness', \n           'loudness', 'speechiness', 'tempo', 'valence', \n           'sadness', 'joy', 'love', 'anger', 'fear', 'surprise',\n           'LABEL_0', 'LABEL_1', 'LABEL_2', 'NEGATIVE', 'POSITIVE']]\n\n# Find the pearson correlations matrix\ncorr = track_sentiment_df.corr(method = 'pearson')\n\n\n\nThe code below produces a scatterplot that showcases the correlation between energy and fear. The x-axis represents the energy value, while the y-axis represents the fear sentiment. The size of each data point corresponds to the label indicating the neutral sentiment level, and its color represents the valence value. Moreover, each bubble contains its energy value within, allowing for a straightforward interpretation of the data.\n\n\nSimilarly, the scatterplot presented above utilizes the track sentiment data, comparing the energy and fear levels of the tracks based on valence and size.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#principal-component-analysis",
    "href": "index.html#principal-component-analysis",
    "title": "NLP Song Lyrics",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\nPrincipal Component Analysis (PCA) is a unsupervised dimension reduction algorithm. We implement PCA on a range of track audio features as well as emotional sentiments such as sadness, joy, love, anger, and more from our data. This lets us transform the data into fewer columns, reducing the dimensionality without losing significant information.\nAfter performing PCA on the data, we apply it to generate a biplot depicting the relationship between the features and tracks. This biplot quickly reveals any discernible patterns and clusters within the dataset.\n\nX_SMALL = df_final[['acousticness', 'danceability', 'energy', 'speechiness', \n                    'tempo', 'valence', 'sadness', 'joy', 'love', 'anger', \n                    'fear', 'surprise', 'name', 'LABEL_0', 'LABEL_1', 'LABEL_2']]\n\nWe use the PCA and StandardScaler modules from the sklearn library. First, we select the first 12 columns from our data subset and form a matrix, named \\(X_i\\). We then standardize the data. Next, we apply PCA to the standardized data, \\(X_{st}\\). Lastly, we save the obtained loadings and eigenvalues.\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Standard scaling track audio features\nX_i = X_SMALL.iloc[:,0:12]\nX_st =  StandardScaler().fit_transform(X_i)\n\n# Apply PCA to scaled data\npca = PCA()\npca_out = pca.fit(X_st)\n\n# component loadings\nloadings = pca_out.components_\n\n# get eigenvalues (variance explained by each PC)  \npca_out.explained_variance_\n\narray([2.65011368e+00, 1.78220617e+00, 1.32078217e+00, 1.23927771e+00,\n       1.13536483e+00, 1.04777115e+00, 8.75900205e-01, 7.54116010e-01,\n       6.06658820e-01, 5.67131303e-01, 2.65575917e-01, 7.98632974e-15])\n\n\nNext, the following code uses the PCA() function to calculate the PCA scores of the standardized data set, \\(X_{st}\\).\n\nfeatures = X_i.columns.values # Labels\ncomponents = pca.fit_transform(X_st) # PCA Score\nloadings = pca_out.components_.T * np.sqrt(pca_out.explained_variance_)\n\nA biplot is generated based on the PCA scores and loadings, and the column names of the \\(X_i\\) data frame are used as labels for the plot. The variance explained by the first two principal components are also displayed on the plot.\n\n\n                                                \n\n\nBelow is a preview of all the PCA clustered groups.\n\n\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\nPC11\nPC12\n\n\n\n\n0\n-0.652941\n-0.540595\n0.277601\n-1.276863\n0.412919\n-0.207641\n-0.019832\n0.451893\n-0.773699\n-0.432625\n0.148075\n-1.635591e-08\n\n\n1\n-1.192109\n3.319574\n-0.687571\n1.032594\n0.775812\n-0.537727\n-1.541805\n-0.796704\n-0.756995\n0.949406\n-0.429861\n8.099381e-08\n\n\n2\n1.080397\n0.204470\n1.129465\n-0.305987\n0.566007\n0.881001\n-0.641871\n0.360368\n0.671404\n0.286174\n-0.287698\n-1.186518e-07\n\n\n3\n-1.306320\n-0.990882\n0.597186\n-1.050503\n0.141820\n-0.638868\n-0.483447\n0.085446\n0.096276\n0.019933\n0.731528\n7.415103e-09\n\n\n4\n-1.335645\n-1.277782\n-0.085476\n-1.018065\n0.395467\n0.719844\n-0.612023\n0.245817\n-0.426194\n0.805717\n0.072715\n-9.832706e-08\n\n\n\n\n\n\n\n\nThe variance ratios for the PCA output and the cumulative sum of the explained variance ratios are printed below. Specifically, the array displayed represents the amount of variability explained by each component.\n\nprint(pca_out.explained_variance_ratio_)\nprint('----')\nprint(pca_out.explained_variance_ratio_.cumsum())\n\n[2.16425951e-01 1.45546837e-01 1.07863877e-01 1.01207680e-01\n 9.27214608e-02 8.55679769e-02 7.15318501e-02 6.15861408e-02\n 4.95438036e-02 4.63157231e-02 2.16886999e-02 6.52216928e-16]\n----\n[0.21642595 0.36197279 0.46983667 0.57104434 0.66376581 0.74933378\n 0.82086563 0.88245177 0.93199558 0.9783113  1.         1.        ]\n\n\nThe loading vectors help visualize the relationship between the original variables and their respective components. These vectors represent the weights of the variables within a mathematical equation used to generate the principal components.\n\ndf_weights = pd.DataFrame(pca_out.components_.T, columns=df_pca.columns, index=X_i.columns)\ndf_weights\n\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\nPC11\nPC12\n\n\n\n\nacousticness\n0.253094\n0.425560\n-0.081137\n-0.051999\n0.120657\n-0.270423\n0.038467\n0.565513\n-0.512979\n-0.059977\n-0.264270\n-2.786806e-08\n\n\ndanceability\n-0.428916\n0.327036\n-0.026959\n-0.109895\n0.101021\n0.030147\n-0.217469\n0.138922\n0.523550\n-0.012503\n-0.586779\n4.801649e-10\n\n\nenergy\n-0.309072\n-0.169597\n-0.250304\n0.309696\n-0.430665\n0.106693\n0.308849\n0.025428\n-0.270576\n0.482465\n-0.343909\n-2.016976e-08\n\n\nspeechiness\n-0.188700\n0.395047\n-0.062115\n-0.032742\n-0.118204\n0.304929\n0.670314\n-0.052322\n0.033915\n-0.472329\n0.141921\n6.140892e-09\n\n\ntempo\n0.102180\n0.112419\n0.250471\n0.222759\n-0.388726\n-0.698286\n0.097755\n-0.348045\n0.104721\n-0.220550\n-0.188555\n9.069694e-09\n\n\nvalence\n-0.437115\n0.155936\n0.052694\n0.248609\n-0.017721\n-0.338282\n-0.003064\n0.417016\n0.182694\n0.208423\n0.595445\n-1.736405e-08\n\n\nsadness\n0.396350\n0.061848\n-0.457667\n-0.064144\n-0.420210\n0.034624\n-0.077819\n0.190498\n0.359314\n0.010301\n0.101546\n5.156194e-01\n\n\njoy\n-0.412556\n-0.266452\n0.186634\n-0.496523\n-0.074336\n-0.157048\n0.007957\n0.032509\n-0.274236\n-0.148999\n-0.020153\n5.901792e-01\n\n\nlove\n-0.030564\n-0.320082\n-0.212120\n0.566633\n0.503138\n-0.097366\n0.140785\n0.062050\n0.057297\n-0.303900\n-0.150700\n3.548201e-01\n\n\nanger\n-0.128199\n0.542932\n-0.134174\n0.206550\n0.133607\n0.089812\n-0.313582\n-0.502087\n-0.289683\n0.161095\n0.126852\n3.547164e-01\n\n\nfear\n0.270561\n0.132370\n0.620053\n0.077554\n0.159411\n0.149327\n0.334458\n0.064617\n0.185699\n0.427809\n-0.083975\n3.612335e-01\n\n\nsurprise\n-0.038259\n-0.024411\n0.410989\n0.395483\n-0.381912\n0.392240\n-0.401021\n0.254973\n-0.134342\n-0.353076\n-0.027541\n6.012030e-02",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#k-means-clustering",
    "href": "index.html#k-means-clustering",
    "title": "NLP Song Lyrics",
    "section": "K Means Clustering",
    "text": "K Means Clustering\n\nClustering is an unsupervised machine learning technique used to categorize data points into distinct groups based on their similarities. In Spotify data, for example, clustering can categorize songs into genres or moods by analyzing characteristics like tempo, beat, and instrumentals.\n\nNext, we apply K-means clustering on the dimensionally reduced Spotify data to explore patterns in track audio features and sentiment. K-means is an unsupervised algorithm that optimizes the number of clusters (\\(K\\)). We use the Elbow method to determine the optimal \\(K\\).\nAs shown below, we use the KMeans algorithm from the sklearn.cluster library to categorize songs based on features like energy levels and sound qualities. Applying this to the “playlist_tracks” dataset, we create three clusters, excluding the “artist” and “name” columns to focus on track features.\n\nfrom sklearn.cluster import KMeans\nplaylist_tracks = df_final[['name','acousticness','danceability','energy', 'liveness', \n                            'instrumentalness','speechiness','valence',\n                            'sadness', 'joy', 'love', 'anger', 'fear', ]]#'surprise'\n\nkmeans = KMeans(n_clusters = 3)\nkmeans.fit(playlist_tracks.drop(['name'], axis = 1))\n\nKMeans(n_clusters=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(n_clusters=3)\n\n\n\n\n                                                \n\n\n\nVisualizing the Clusters\nMoving forward, let’s look at differences in the audio features of each group.\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(playlist_tracks.drop(['name'], axis = 1))\nscaled_data = scaler.transform(playlist_tracks.drop(['name'], axis = 1))\n\n\n\nCode\nfrom sklearn.decomposition import PCA\npca = PCA(n_components =2)\npca.fit(scaled_data)\ndata_pca = pca.transform(scaled_data)\n\n\n\n\nText(0, 0.5, 'PC2: 0.153')\n\n\n\n\n\n\n\n\n\n\nplaylist_tracks['group'] = list(kmeans.labels_)\nplaylist_tracks = playlist_tracks.astype({'group': str})\n\nmeans = pd.DataFrame(index = range(0,3), \n                    columns = list(playlist_tracks[playlist_tracks['group'] == '0'].describe().loc['mean'].index))\nmeans.iloc[0] = playlist_tracks[playlist_tracks['group'] == '0'].describe().loc['mean']\nmeans.iloc[1] = playlist_tracks[playlist_tracks['group'] == '1'].describe().loc['mean']\nmeans.iloc[2] = playlist_tracks[playlist_tracks['group'] == '2'].describe().loc['mean']\nmeans\n\n\n\n\n\n\n\n\n\nacousticness\ndanceability\nenergy\nliveness\ninstrumentalness\nspeechiness\nvalence\nsadness\njoy\nlove\nanger\nfear\n\n\n\n\n0\n0.20839\n0.672\n0.60875\n0.144285\n0.020388\n0.059735\n0.54265\n0.151202\n0.108936\n0.206101\n0.253816\n0.259347\n\n\n1\n0.126155\n0.74595\n0.67765\n0.110685\n0.017031\n0.052625\n0.6812\n0.028329\n0.854914\n0.046817\n0.0533\n0.013642\n\n\n2\n0.3229\n0.615\n0.6254\n0.13608\n0.000763\n0.0478\n0.4399\n0.893231\n0.046527\n0.002716\n0.032235\n0.023872\n\n\n\n\n\n\n\n\n\n\n\nOrganized Songs in a Playlist\nK-means is an unsupervised clustering algorithm that partitions data into \\(K\\) clusters, grouping similar points together. Using Spotify data, we can cluster songs based on attributes like acousticness, danceability, and energy. We import Python libraries such as pandas, matplotlib, and sklearn for data manipulation, visualization, and clustering. After obtaining song attributes, we use the describe function to gain insights and prepare the data for clustering, as demonstrated below.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import cluster, decomposition\n\nsongs = df_final[['name','acousticness', 'danceability', 'energy', 'instrumentalness', \n            'liveness', 'speechiness', 'valence',  'loudness_scaled', \n            'anger', 'love', 'sadness']]\nsongs.describe()\n\n\n\n\n\n\n\n\n\nacousticness\ndanceability\nenergy\ninstrumentalness\nliveness\nspeechiness\nvalence\nloudness_scaled\nanger\nlove\nsadness\n\n\n\n\ncount\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n50.000000\n\n\nmean\n0.198398\n0.690180\n0.639640\n0.015120\n0.129204\n0.054504\n0.577520\n0.551367\n0.129293\n0.101710\n0.250459\n\n\nstd\n0.194310\n0.144655\n0.130139\n0.059203\n0.079672\n0.032362\n0.234215\n0.221284\n0.244960\n0.245032\n0.356076\n\n\nmin\n0.000938\n0.264000\n0.386000\n0.000000\n0.029300\n0.026400\n0.190000\n0.000000\n0.000206\n0.000193\n0.001261\n\n\n25%\n0.040675\n0.630500\n0.552000\n0.000000\n0.082600\n0.034775\n0.373000\n0.376041\n0.002251\n0.002018\n0.007991\n\n\n50%\n0.140000\n0.700500\n0.635000\n0.000003\n0.106000\n0.046450\n0.591500\n0.581936\n0.026904\n0.006858\n0.041605\n\n\n75%\n0.270750\n0.780000\n0.727250\n0.000082\n0.139250\n0.063300\n0.775500\n0.699484\n0.124115\n0.032315\n0.401728\n\n\nmax\n0.799000\n0.936000\n0.946000\n0.336000\n0.403000\n0.204000\n0.957000\n1.000000\n0.993250\n0.994453\n0.998848\n\n\n\n\n\n\n\n\nThe first step is to extract song labels from the dataset. We then select key features to input into the Affinity Propagation clustering algorithm from the scikit-learn library. We set a preference value of -200 to optimize clustering performance. After inputting the data, we train the algorithm to cluster the Spotify songs effectively.\n\nlabels = songs.values[:,0]\nX = songs.values[:,1:12]\nkmeans = cluster.AffinityPropagation()\nkmeans.fit(X)\n\nAffinityPropagation()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.AffinityPropagationAffinityPropagation()\n\n\n\n\nCategory 0\n-----\nPlease Please Please\nNot Like Us\nBeautiful Things\nLUNCH\nEnd of Beginning\nBelong Together\nSlow It Down\nthe boy is mine\n360\nRockstar\nOne Of The Girls (with JENNIE, Lily Rose Depp)\nParking Lot\nGata Only\nSanta\nMagnetic\n\nCategory 1\n-----\nSi Antes Te Hubiera Conocido\nNasty\ngreedy\nBAND4BAND (feat. Lil Baby)\n\nCategory 2\n-----\nBIRDS OF A FEATHER\nwe can't be friends (wait for your love)\nTough\nFortnight (feat. Post Malone)\nClose To You\nStumblin' In\nScared To Start\n\nCategory 5\n-----\nGood Luck, Babe!\nA Bar Song (Tipsy)\nMILLION DOLLAR BABY\nToo Sweet\nI Had Some Help (Feat. Morgan Wallen)\nEspresso\ni like the way you kiss me\nHoudini\nI Don't Wanna Wait\nSmeraldo Garden Marching Band (feat. Loco)\nWater\nIllusion\n\nCategory 3\n-----\nStargazing\nLose Control\nAustin\nI Can Do It With a Broken Heart\nGIRLS\nSaturn\nStick Season\nLies Lies Lies\nfeelslikeimfallinginlove\n\nCategory 4\n-----\nHOT TO GO!\nMove\n28\n\n\n\nThe script effectively categorized the playlist into six distinct groups based on shared features, resulting in a diverse selection of songs within each category.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#supervised-learning-similarity-search",
    "href": "index.html#supervised-learning-similarity-search",
    "title": "NLP Song Lyrics",
    "section": "Supervised Learning: Similarity Search",
    "text": "Supervised Learning: Similarity Search\nWe create a query to retrieve similar songs based on Euclidean distance, where a shorter distance indicates greater similarity. Additionally, we employ the K-nearest neighbors (KNN) algorithm, a supervised learning method that classifies songs based on known data.\n\nKNN Algorithm\n\nK-nearest neighbors (KNN) is a supervised algorithm for classification and regression. It predicts the category of new data points by comparing them to the K nearest neighbors with known classifications. For example, KNN can classify Spotify songs by analyzing their features and comparing them to similar, previously classified tracks.\n\nThe KNN algorithm identifies \\(k\\) similar elements around a query point. Using the knnQuery function, we input a query point (a specific song and artist), characteristic points, and a value for \\(k\\). This function calculates the Euclidean distance between the query point and each data point, returning the \\(k\\) closest points.\nThe querySimilars function then applies KNN to find and return the \\(k\\) most similar songs based on specified features.\n\n# Get a song string search\ndef getMusicName(elem):\n    return f\"{elem['artist']} - {elem['name']}\"\n\ndef knnQuery(queryPoint, arrCharactPoints, k):\n    queryVals = queryPoint.tolist()\n    distVals = []\n    \n    # Copy of data indices and data\n    tmp = arrCharactPoints.copy(deep = True)  \n    for index, row in tmp.iterrows():\n        feat = row.values.tolist()\n        \n        # Calculate sum of squared differences\n        ssd = sum(abs(feat[i] - queryVals[i]) ** 2 for i in range(len(queryVals)))\n        \n        # Get euclidean distance\n        distVals.append(ssd ** 0.5)\n        \n    tmp['distance'] = distVals\n    tmp = tmp.sort_values('distance')\n    \n    # K closest and furthest points\n    return tmp.head(k).index, tmp.tail(k).index\n\n\n# Execute KNN removing the query point\ndef querySimilar(df, columns, idx, func, param):\n    arr = df[columns].copy(deep = True)\n    queryPoint = arr.loc[idx]\n    arr = arr.drop([idx])\n    return func(queryPoint, arr, param)\n\nKNN Query Example.\nNow we perform a KNN query to find the k most similar songs based on specified features. We first establish a function to generate custom query points. The code snippet below then selects specific song features and finds the top \\(k\\) values within that feature set.\n\nLet’s search for \\(k=3\\) similar songs to a query point \\(\\textrm{songIndex} = 6\\).\n\n# Select song and column attributes\nsongIndex = 4 # query point\ncolumns = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', \n           'loudness_scaled', 'tempo', \n           'speechiness', 'valence']\n\n# Set query parameters\nfunc, param = knnQuery,3\n\n# Implement query\nresponse = querySimilar(df, columns, songIndex, func, param)\n\nprint(\"---- Query Point ----\")\nprint(getMusicName(df.loc[songIndex]))\nprint('---- k = 3 similar songs ----')\nfor track_id in response[0]:\n    track_name = getMusicName(df.loc[track_id])\n    print(track_name)\nprint('---- k = 3 nonsimilar songs ----')\nfor track_id in response[1]:\n    track_name = getMusicName(df.loc[track_id])\n    print(track_name)\n\n---- Query Point ----\nShaboozey - A Bar Song (Tipsy)\n---- k = 3 similar songs ----\nMorgan Wallen - Lies Lies Lies\nZach Bryan - 28\nThe Weeknd - One Of The Girls (with JENNIE, Lily Rose Depp)\n---- k = 3 nonsimilar songs ----\nSZA - Saturn\nBenson Boone - Slow It Down\nTaylor Swift - Fortnight (feat. Post Malone)\n\n\nThe code below extends the KNN algorithm to query each track in a playlist rather than a single defined query point.\nTo track the number of similar and non-similar songs, we use two dictionaries: similar_count and nonsimilar_count. A loop iterates through the playlist, running the querySimilars function on each track. The results are processed into “similar” and “non-similar” categories stored in the response variable.\n\nsimilar_count = {} # Similar songs count\nnonsimilar_count = {} # Non-similar songs count\n\nfor track_index in df.index:\n    # Implement query\n    response = querySimilar(df, columns, track_index, func, param)\n    \n    # Get similar songs\n    for similar_index in response[0]:\n        track = getMusicName(df.loc[similar_index])\n        if track in similar_count:\n            similar_count[track] += 1\n        else:\n            similar_count[track] = 1\n    \n    # Get non-similar songs\n    for nonsimilar_index in response[1]:\n        track = getMusicName(df.loc[nonsimilar_index])\n        if track in nonsimilar_count:\n            nonsimilar_count[track] += 1\n        else:\n            nonsimilar_count[track] = 1\n\n\n\n---- NON SIMILAR SONG COUNTS ----\nBenson Boone - Slow It Down : 39\nTaylor Swift - Fortnight (feat. Post Malone) : 39\nSZA - Saturn : 36\nZach Bryan - 28 : 14\nMorgan Wallen - Lies Lies Lies : 11\nShaboozey - A Bar Song (Tipsy) : 11\n\n---- SIMILAR SONG COUNTS ----\nRvssian - Santa : 6\nDua Lipa - Illusion : 5\nHozier - Too Sweet : 5\nThe Weeknd - One Of The Girls (with JENNIE, Lily Rose Depp) : 5\nMustard - Parking Lot : 5\nTinashe - Nasty : 5\nChappell Roan - Good Luck, Babe! : 5\nDjo - End of Beginning : 5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/01_data.html",
    "href": "01_sentiment_analysis/01_data.html",
    "title": "Extracting Spotify Data",
    "section": "",
    "text": "Getting started, we want to extract data for a set of tracks within one of Spotify’s top-featured playlists. Leveraging the Spotify Web API, we can seamlessly obtain detailed data for a song, such as the performing artist, the album it belongs to, its release date, popularity, and audio features like danceability, energy, and tempo.\nPython libraries like spotipy offer a user-friendly way to interact with the Spotify API, offering a range of functions that streamline tasks like API authentication, retrieving playlist data, and obtaining information about any given song.\n\nAccessing the Spotify Web API\nTo access data from Spotify, we import the spotipy library and the SpotifyClientCredentials module. Additionally, we utilize the pandas package for data manipulation and display. In order to authenticate our access to the Spotify API, we must provide our client ID and client secret to a client credentials manager. Once authenticated, we can use the spotipy module to interact with the Spotify API and retrieve data.\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport pandas as pd\n\nclient_id = \"xxx\"\nclient_secret = \"xxx\"\nmy_auth = SpotifyClientCredentials(client_id, client_secret)\nsp = spotipy.Spotify(auth_manager=my_auth)\n\n\nSpotify’s Featured Playlists\nLet’s take a look at the popular Spotify playlists. Below, the code retrieves a range of Spotify playlists and generates a dataframe containing details for each playlist, including its name, ID, description, thumbnail, total number of tracks, and follower count. The resulting dataframe is displayed as an HTML table.\n\nusername = \"spotify\"\nspotify_playlists = sp.user_playlists(username)\ntop_playlists = get_top_playlists(username, 6)\n\nThe function get_top_playlists retrieves all playlists for a given user and returns the playlists with the most followers. Specifically, the function gets all playlists from a given user, iterating over each playlist item to extract the thumbnail image URL, the playlist name, ID, description, total number of tracks, and follower count for the playlist. It then creates a DataFrame from the playlist data, sorts the DataFrame by the number of followers in descending order, and returns the top playlists with the most followers.\n\n\n\n\n\n\n\nthumbnail\nname\nid\ndescription\ntracks\nfollowers\n\n\n\n\n0\n\nToday’s Top Hits\n37i9dQZF1DXcBWIGoYBM5M\nKarol G is on top of the Hottest 50!\n50\n34735922\n\n\n1\n\nRapCaviar\n37i9dQZF1DX0XUsuxWHRQd\nNew music from Eminem, Ice Spice and BossMan DLow.\n50\n15979449\n\n\n3\n\nViva Latino\n37i9dQZF1DX10zKzsJ2jva\nToday's top Latin hits, elevando nuestra música. Cover: Natanael Cano, Oscar Maydon\n50\n15144445\n\n\n12\n\nAll Out 2000s\n37i9dQZF1DX4o1oenSJRJd\nThe biggest songs of the 2000s. Cover: The Killers\n150\n12331870\n\n\n7\n\nRock Classics\n37i9dQZF1DWXRqgorJj26U\nRock legends & epic songs that continue to inspire generations. Cover: The Rolling Stones\n200\n12205175\n\n\n14\n\nAll Out 80s\n37i9dQZF1DX4UtSsGT1Sbe\nThe biggest songs of the 1980s. Cover: Bruce Springsteen\n150\n11312274\n\n\n\n\n\n\n\n\n\n\nExtracting Tracks From a Playlist\nThe following script enables the compilation of song and artist data from any Spotify playlist through its URI. To analyze a particular playlist, simply copy the URI from the Spotify Player interface and input it into the function defined below. The get_playlist_tracks method returns a complete list of track IDs and corresponding artists from the selected playlist.\n\ndef get_playlist_tracks(playlist_URI):\n    tracks = []\n    results = sp.playlist_tracks(playlist_URI)\n    tracks = results[\"items\"]\n    while results[\"next\"]:\n        results = sp.next(results)\n        tracks.extend(results[\"items\"])\n    return tracks\n\n\nExtracting Features from Tracks\nThe following script utilizes Spotify’s API to extract further details about each song within the playlist. It obtains metadata such as the track name, the artist it’s sung by, the album it belongs to, the release date, and track features such as danceability, tempo, and popularity.\n\ndef playlist_features(id, artist_id, playlist_id):\n    meta = sp.track(id)\n    audio_features = sp.audio_features(id)\n    artist_info = sp.artist(artist_id)\n    playlist_info = sp.playlist(playlist_id)\n\n    # print(audio_features)\n\n    if audio_features[0] is None:\n        return None\n    \n    \n\n    name = meta['name']\n    track_id = meta['id']\n    album = meta['album']['name']\n    artist = meta['album']['artists'][0]['name']\n    artist_id = meta['album']['artists'][0]['id']\n    release_date = meta['album']['release_date']\n    length = meta['duration_ms']\n    popularity = meta['popularity']\n\n    artist_pop = artist_info[\"popularity\"]\n    artist_genres = artist_info[\"genres\"]\n    artist_followers = artist_info[\"followers\"]['total']\n\n    acousticness = audio_features[0]['acousticness']\n    danceability = audio_features[0]['danceability']\n    energy = audio_features[0]['energy']\n    instrumentalness = audio_features[0]['instrumentalness']\n    liveness = audio_features[0]['liveness']\n    loudness = audio_features[0]['loudness']\n    speechiness = audio_features[0]['speechiness']\n    tempo = audio_features[0]['tempo']\n    valence = audio_features[0]['valence']\n    key = audio_features[0]['key']\n    mode = audio_features[0]['mode']\n    time_signature = audio_features[0]['time_signature']\n    \n    playlist_name = playlist_info['name']\n\n    return [name, track_id, album, artist, artist_id, release_date, length, popularity, \n            artist_pop, artist_genres, artist_followers, acousticness, danceability, \n            energy, instrumentalness, liveness, loudness, speechiness, \n            tempo, valence, key, mode, time_signature, playlist_name]\n\nChoose a specific playlist to analyze by copying the URL from the Spotify Player interface. Using that link, the playlist_tracks method retrieves a list of IDs and corresponding artists for each track from the playlist. Specifically, we analyze Spotify’s Today’s Top Hits playlist.\n\nplaylist_links = [top_playlists['id'][0]]\n\nfor playlist_URI in playlist_links:\n    # playlist_URI = link.split(\"/\")[-1].split(\"?\")[0]\n    \n    all_tracks = [  # Loop over track ids\n    playlist_features(i[\"track\"][\"id\"], i[\"track\"][\"artists\"][0][\"uri\"], playlist_URI)\n    for i in get_playlist_tracks(playlist_URI)\n]\n\nPutting it all together, the get_playlist_tracks function retrieves basic details for each song in a specified Spotify playlist using its URI. The playlist_features function then iterates through these tracks using their IDs to extract additional information, such as danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, and more. From there, we create a Pandas dataframe by passing in the extracted information.\n\nLoudness Scaled\n\n# Loudness Scaled\nfrom sklearn import preprocessing \n\nscaler = preprocessing.MinMaxScaler()\n# scale loudness to fit the same range [0, 1]\nloudness2 = df[\"loudness\"].values\nloudness_scaled=scaler.fit_transform(loudness2.reshape(-1, 1))\ndf['loudness_scaled'] = loudness_scaled\n\n\n\n\n\n\n\n\n\n\n\nname\ntrack_id\nalbum\nartist\nartist_id\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\n...\nliveness\nloudness\nspeechiness\ntempo\nvalence\nkey\nmode\ntime_signature\nplaylist\nloudness_scaled\n\n\n\n\n0\nPlease Please Please\n5N3hjp1WNayUPZrA8kJmJP\nPlease Please Please\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-06-06\n186365\n98\n91\n[pop]\n...\n0.1040\n-6.073\n0.0540\n107.071\n0.579\n9\n1\n4\nToday’s Top Hits\n0.575663\n\n\n1\nSi Antes Te Hubiera Conocido\n6WatFBLVB0x077xWeoVc2k\nSi Antes Te Hubiera Conocido\nKAROL G\n790FomKkXshlbRYZFtlgla\n2024-06-21\n195824\n91\n89\n[reggaeton, reggaeton colombiano, trap latino,...\n...\n0.0678\n-6.795\n0.0469\n128.027\n0.787\n11\n1\n4\nToday’s Top Hits\n0.495503\n\n\n2\nBIRDS OF A FEATHER\n6dOtVTDdiauQNBQEDOtlAB\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n210373\n98\n94\n[art pop, pop]\n...\n0.1170\n-10.171\n0.0358\n104.978\n0.438\n2\n1\n4\nToday’s Top Hits\n0.120684\n\n\n3\nGood Luck, Babe!\n0WbMK4wrZ1wFSty9F7FCgu\nGood Luck, Babe!\nChappell Roan\n7GlBOeep6PqTfFi59PTUUN\n2024-04-05\n218423\n94\n86\n[indie pop, pov: indie]\n...\n0.0881\n-5.960\n0.0356\n116.712\n0.785\n11\n0\n4\nToday’s Top Hits\n0.588209\n\n\n4\nA Bar Song (Tipsy)\n2FQrifJ1N335Ljm3TjTVVf\nA Bar Song (Tipsy)\nShaboozey\n3y2cIKLjiOlp1Np37WiUdH\n2024-04-12\n171291\n93\n81\n[pop rap]\n...\n0.0804\n-4.950\n0.0273\n81.012\n0.604\n9\n1\n4\nToday’s Top Hits\n0.700344\n\n\n\n\n5 rows × 25 columns",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Extracting Spotify Data</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html",
    "href": "01_sentiment_analysis/02_nlp.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "Scraping the Web\nTo get started, the script below imports lyricsgenius, a fundamental package libary allowing for web scraping of the Genius Lyrics website to retrieve the lyrics of any given song. Through the initialization of the genius variable, one can access the Genius API and retrieve the lyrics of any given song, such as “Too Many Nights” by Metro Boomin.\nimport lyricsgenius\n\ngenius = lyricsgenius.Genius(\"epFCxujgBe-Y6WrkZedI8kerKxiCpR6Rh0DAHYNlKDf9B4H1nXTdZIkj7krNUHVV\")\nsong = genius.search_song(\"Too Many Nights\", \"Metro Boomin\")\n\nSearching for \"Too Many Nights\" by Metro Boomin...\nDone.\nFirst, we define a function that retrieves the lyrics for any song and artist from the Genius database. As shown below, it first searches for the track using the provided name and artist and then extracts the lyrics from the search results.\ndef get_song_lyrics(song_name, song_artist):\n    song_genius = genius.search_song(song_name, song_artist)\n    song_lyrics = song_genius.lyrics.partition(\"Lyrics\")[2]\n    # Remove any numbers followed by 'Embed'\n    song_lyrics = re.sub(r\"[\\[].*?[\\]]|\\d+Embed\", \"\", song_lyrics)\n    # Remove text between square brackets\n    song_lyrics = re.sub(r\"(\\-[A-Za-z]+\\-)\", \"\", song_lyrics)\n    song_lyrics = re.sub(r'\\d+', '', song_lyrics)\n\n    return song_lyrics",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html#sentiment-analysis",
    "href": "01_sentiment_analysis/02_nlp.html#sentiment-analysis",
    "title": "Natural Language Processing",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nSubsequently, the process involves the implementation of pipeline classes to carry out predictions using models accessible in the Hub. The code imports and employs multiple transformer models specifically designed for text classification and sentiment analysis. Specifically, the following procedure creates three distinct pipelines, each equipped with different models that facilitate the assessment of emotions and sentiment in textual content.\n\nimport transformers\nfrom transformers import pipeline\n\n# Initialize Genius API and sentiment classifiers\nclassifiers = [\n    pipeline(\"text-classification\", model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True),\n    pipeline(\"text-classification\", model='cardiffnlp/twitter-roberta-base-sentiment', return_all_scores=True),\n    pipeline(\"sentiment-analysis\", return_all_scores=True)\n]\n\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\nThe get_lyric_sentiment function takes in pre-processed lyrics as input and produces a dictionary of sentiment scores. It leverages three distinct classifiers to calculate the scores and aggregates them into a final result. For instance, one of these classifiers is the distilbert-base-uncased-emotion model, specifically trained to detect “emotions in texts such as sadness, joy, love, anger, fear, and surprise”.\n\n# Function to perform sentiment analysis\ndef get_lyric_sentiment(lyrics, classifiers):\n    text = ' '.join(lyrics)\n    scores = {}\n    for classifier in classifiers:\n        try:\n            predictions = classifier(text, truncation=True)\n            for prediction in predictions[0]:\n                scores[prediction['label']] = prediction['score']\n        except Exception as e:\n            print(f\"Error during sentiment analysis: {e}\")\n    return scores\n\nIf the lyric sequence contains more than 512 tokens, it will trigger an error message indicating an exception encountered in the ‘embeddings’ layer. However, we have implemented measures to properly manage lyric sequences that exceed 512 words in the function mentioned above.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "01_sentiment_analysis/02_nlp.html#putting-it-all-together",
    "href": "01_sentiment_analysis/02_nlp.html#putting-it-all-together",
    "title": "Natural Language Processing",
    "section": "Putting it All Together",
    "text": "Putting it All Together\nTo summarize, the code efficiently collects data and performs text analysis on every song in a playlist. Specifically, it systematically processes a list of tracks and corresponding artists while simultaneously conducting a thorough cleaning procedure on the lyrics. The cleaning process involves removing all nonessential characters, resulting in a more precise depiction of the song’s content. The outcome is a comprehensive frequency analysis of each word in a song’s lyrics, providing deeper insights into the overall conveyed message.\nAdditionally, the program computes a sentiment score for each song based on the lyrics, indicating whether the lyrics are positive, negative, or neutral. It also collects information about the song and artist, such as the release date, length, popularity, and genre. Finally, the program compiles all this information into a dataframe for further analysis.\n\ntrack_data = []\nfor i, track in all_tracks.iterrows():\n\n    song_name = track[\"name\"] #.partition(\" (\")[0]\n    song_name = track['name'].partition(\" (with\")[0]\n    song_name = song_name.partition(\" - From\")[0]\n    \n    artist_name = track[\"artist\"]\n\n    try:\n        track_lyrics = clean_song_lyrics(song_name, artist_name)\n        stopwords_removed = remove_stopwords_lyrics(track_lyrics)\n        lemmatized = word_lemmatize(stopwords_removed)\n\n        sentiment_scores = get_lyric_sentiment(stopwords_removed, classifiers)\n\n        track_info = track.to_dict()\n        track_info.update(sentiment_scores)\n\n        track_info[\"lyrics\"] = track_lyrics\n        track_info[\"stopwords_removed\"] = stopwords_removed\n        track_info[\"lemmatized\"] = lemmatized\n\n        track_data.append(track_info)\n\n    except Exception as e:\n        print(f\"Error processing track {track['name']} by {track['artist']}: {e}\")\n\ndf_tracks = pd.DataFrame(track_data)\n\nSearching for \"Please Please Please\" by Sabrina Carpenter...\nDone.\nSearching for \"Si Antes Te Hubiera Conocido\" by KAROL G...\nDone.\nSearching for \"BIRDS OF A FEATHER\" by Billie Eilish...\nDone.\nSearching for \"Good Luck, Babe!\" by Chappell Roan...\nDone.\nSearching for \"A Bar Song (Tipsy)\" by Shaboozey...\nDone.\nSearching for \"Not Like Us\" by Kendrick Lamar...\nDone.\nError during sentiment analysis: The expanded size of the tensor (519) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 519].  Tensor sizes: [1, 514]\nSearching for \"MILLION DOLLAR BABY\" by Tommy Richman...\nDone.\nSearching for \"Too Sweet\" by Hozier...\nDone.\nSearching for \"Beautiful Things\" by Benson Boone...\nDone.\nSearching for \"I Had Some Help (Feat. Morgan Wallen)\" by Post Malone...\nDone.\nSearching for \"Espresso\" by Sabrina Carpenter...\nDone.\nSearching for \"i like the way you kiss me\" by Artemas...\nDone.\nSearching for \"Stargazing\" by Myles Smith...\nDone.\nSearching for \"LUNCH\" by Billie Eilish...\nDone.\nSearching for \"End of Beginning\" by Djo...\nDone.\nSearching for \"we can't be friends (wait for your love)\" by Ariana Grande...\nDone.\nSearching for \"Lose Control\" by Teddy Swims...\nDone.\nSearching for \"Tough\" by Quavo...\nDone.\nSearching for \"Austin\" by Dasha...\nDone.\nSearching for \"I Can Do It With a Broken Heart\" by Taylor Swift...\nDone.\nSearching for \"Houdini\" by Eminem...\nDone.\nSearching for \"Nasty\" by Tinashe...\nDone.\nSearching for \"Belong Together\" by Mark Ambor...\nDone.\nSearching for \"Slow It Down\" by Benson Boone...\nDone.\nSearching for \"HOT TO GO!\" by Chappell Roan...\nDone.\nSearching for \"GIRLS\" by The Kid LAROI...\nDone.\nSearching for \"greedy\" by Tate McRae...\nDone.\nSearching for \"Move\" by Adam Port...\nDone.\nSearching for \"Fortnight (feat. Post Malone)\" by Taylor Swift...\nDone.\nSearching for \"Saturn\" by SZA...\nDone.\nSearching for \"28\" by Zach Bryan...\nDone.\nSearching for \"Close To You\" by Gracie Abrams...\nDone.\nSearching for \"the boy is mine\" by Ariana Grande...\nDone.\nSearching for \"Stick Season\" by Noah Kahan...\nDone.\nSearching for \"I Don't Wanna Wait\" by David Guetta...\nDone.\nSearching for \"Smeraldo Garden Marching Band (feat. Loco)\" by Jimin...\nDone.\nSearching for \"Stumblin' In\" by CYRIL...\nDone.\nSearching for \"360\" by Charli xcx...\nDone.\nSearching for \"Rockstar\" by LISA...\nDone.\nSearching for \"One Of The Girls\" by The Weeknd...\nDone.\nSearching for \"Scared To Start\" by Michael Marcagi...\nDone.\nSearching for \"Lies Lies Lies\" by Morgan Wallen...\nDone.\nSearching for \"feelslikeimfallinginlove\" by Coldplay...\nDone.\nSearching for \"Parking Lot\" by Mustard...\nDone.\nSearching for \"Gata Only\" by FloyyMenor...\nDone.\nSearching for \"BAND4BAND (feat. Lil Baby)\" by Central Cee...\nDone.\nSearching for \"Santa\" by Rvssian...\nDone.\nSearching for \"Magnetic\" by ILLIT...\nDone.\nSearching for \"Water\" by Tyla...\nDone.\nSearching for \"Illusion\" by Dua Lipa...\nDone.\n\n\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n\n\n\n#df_tracks = pd.DataFrame(track_data)\ndf_tracks.to_csv(\"../assets/data/all_tracks+lyrics.csv\", index=False)\n\n\ndf_tracks\n\n\n\n\n\n\n\n\n\nname\ntrack_id\nalbum\nartist\nartist_id\nrelease_date\nlength\npopularity\nartist_pop\nartist_genres\n...\nfear\nsurprise\nLABEL_0\nLABEL_1\nLABEL_2\nNEGATIVE\nPOSITIVE\nlyrics\nstopwords_removed\nlemmatized\n\n\n\n\n0\nPlease Please Please\n5N3hjp1WNayUPZrA8kJmJP\nPlease Please Please\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-06-06\n186365\n98\n91\n['pop']\n...\n0.000637\n0.000841\n0.251058\n0.542962\n0.205980\n0.857851\n0.142149\n[i, know, i, have, good, judgment, i, know, i,...\n[know, good, judgment, know, good, taste, funn...\n[know, good, judgment, know, good, taste, funn...\n\n\n1\nSi Antes Te Hubiera Conocido\n6WatFBLVB0x077xWeoVc2k\nSi Antes Te Hubiera Conocido\nKAROL G\n790FomKkXshlbRYZFtlgla\n2024-06-21\n195824\n91\n89\n['reggaeton', 'reggaeton colombiano', 'trap la...\n...\n0.001239\n0.000147\n0.030611\n0.523545\n0.445844\n0.966250\n0.033750\n[what, what, we, are, ready, to, rule, summer,...\n[ready, rule, summer, started, fire, would, me...\n[ready, rule, summer, start, fire, would, meet...\n\n\n2\nBIRDS OF A FEATHER\n6dOtVTDdiauQNBQEDOtlAB\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n210373\n98\n94\n['art pop', 'pop']\n...\n0.434426\n0.034063\n0.122799\n0.504202\n0.372999\n0.959893\n0.040107\n[i, want, you, to, stay, til, i, am, in, the, ...\n[want, stay, til, grave, til, rot, away, dead,...\n[want, stay, til, grave, til, rot, away, dead,...\n\n\n3\nGood Luck, Babe!\n0WbMK4wrZ1wFSty9F7FCgu\nGood Luck, Babe!\nChappell Roan\n7GlBOeep6PqTfFi59PTUUN\n2024-04-05\n218423\n94\n86\n['indie pop', 'pov: indie']\n...\n0.000427\n0.000471\n0.343443\n0.554660\n0.101897\n0.981645\n0.018355\n[it, is, fine, it, is, cool, you, can, say, th...\n[fine, cool, say, nothing, know, truth, guess,...\n[fine, cool, say, nothing, know, truth, guess,...\n\n\n4\nA Bar Song (Tipsy)\n2FQrifJ1N335Ljm3TjTVVf\nA Bar Song (Tipsy)\nShaboozey\n3y2cIKLjiOlp1Np37WiUdH\n2024-04-12\n171291\n93\n81\n['pop rap']\n...\n0.009928\n0.003751\n0.057218\n0.763994\n0.178788\n0.994249\n0.005751\n[my, baby, want, a, barking, she, is, been, te...\n[baby, want, barking, telling, night, long, ga...\n[baby, want, bark, tell, night, long, gasoline...\n\n\n5\nNot Like Us\n6AI3ezQ4o3HUoP6Dhudph3\nNot Like Us\nKendrick Lamar\n2YZyLoL8N0Wb9xBt1NhZWg\n2024-05-04\n274192\n96\n92\n['conscious hip hop', 'hip hop', 'rap', 'west ...\n...\n0.007257\n0.004582\nNaN\nNaN\nNaN\n0.997331\n0.002669\n[psst, i, see, dead, people, mustard, on, the,...\n[psst, see, dead, people, mustard, beat, musta...\n[psst, see, dead, people, mustard, beat, musta...\n\n\n6\nMILLION DOLLAR BABY\n7fzHQizxTqy8wTXwlrgPQQ\nMILLION DOLLAR BABY\nTommy Richman\n1WaFQSHVGZQJTbf0BdxdNo\n2024-04-26\n155151\n86\n83\n['chill abstract hip hop']\n...\n0.032734\n0.004189\n0.280416\n0.655696\n0.063888\n0.992852\n0.007148\n[do, it, baby, do, what, i, should, think, do,...\n[baby, think, baby, could, think, baby, think,...\n[baby, think, baby, could, think, baby, think,...\n\n\n7\nToo Sweet\n4IadxL6BUymXlh8RCJJu7T\nUnheard\nHozier\n2FXC3k01G6Gw61bmprjgqS\n2024-03-22\n251424\n83\n85\n['irish singer-songwriter', 'modern rock', 'po...\n...\n0.002293\n0.001093\n0.120370\n0.648945\n0.230685\n0.984314\n0.015686\n[it, can, not, be, said, i, am, an, early, bir...\n[said, early, bird, clock, say, word, baby, ne...\n[say, early, bird, clock, say, word, baby, nev...\n\n\n8\nBeautiful Things\n6tNQ70jh4OwmPGpYy6R2o9\nBeautiful Things\nBenson Boone\n22wbnEMDvgVIAGdFeek6ET\n2024-01-18\n180304\n91\n85\n['singer-songwriter pop']\n...\n0.996488\n0.000843\n0.033857\n0.318134\n0.648009\n0.012351\n0.987649\n[for, a, while, there, it, was, rough, but, la...\n[rough, lately, better, last, four, cold, reme...\n[rough, lately, well, last, four, cold, rememb...\n\n\n9\nI Had Some Help (Feat. Morgan Wallen)\n7221xIgOnuakPdLqT0F3nP\nI Had Some Help\nPost Malone\n246dkjvS1zLTtiykXe5h60\n2024-05-10\n178205\n95\n90\n['dfw rap', 'melodic rap', 'pop', 'rap']\n...\n0.000706\n0.000557\n0.210037\n0.717910\n0.072052\n0.998456\n0.001544\n[you, got, a, got, ta, nerve, do, not, you, ba...\n[got, got, ta, nerve, baby, hit, curb, made, t...\n[get, get, ta, nerve, baby, hit, curb, make, t...\n\n\n10\nEspresso\n2qSkIjg1o9h3YT9RAgYN75\nEspresso\nSabrina Carpenter\n74KM79TiuVKeVCqs8QtB0B\n2024-04-12\n175459\n99\n91\n['pop']\n...\n0.027107\n0.004054\n0.070886\n0.800304\n0.128810\n0.992557\n0.007443\n[now, he, is, thinking, about, me, every, nigh...\n[thinking, every, night, sweet, guess, say, sl...\n[think, every, night, sweet, guess, say, sleep...\n\n\n11\ni like the way you kiss me\n2GxrNKugF82CnoRFbQfzPf\ni like the way you kiss me\nArtemas\n0PCCGZ0wGLizHt2KZ7hhA2\n2024-03-19\n142514\n95\n81\n[]\n...\n0.001377\n0.001145\n0.034661\n0.521730\n0.443609\n0.984495\n0.015505\n[i, like, the, way, you, kiss, me, i, like, th...\n[like, way, kiss, like, way, uh, like, way, ki...\n[like, way, kiss, like, way, uh, like, way, ki...\n\n\n12\nStargazing\n3Vr3zh0r7ALn8VLqCiRR10\nStargazing\nMyles Smith\n3bO19AOone0ubCsfDXDtYt\n2024-05-10\n172533\n92\n78\n['singer-songwriter pop']\n...\n0.000203\n0.000153\n0.479969\n0.450779\n0.069251\n0.994339\n0.005661\n[oohooh, oohooh, oohooh, time, stood, still, j...\n[oohooh, oohooh, oohooh, time, stood, still, l...\n[oohooh, oohooh, oohooh, time, stand, still, l...\n\n\n13\nLUNCH\n629DixmZGHc7ILtEntuiWE\nHIT ME HARD AND SOFT\nBillie Eilish\n6qqNVTkY8uBg9cP3Jd7DAH\n2024-05-17\n179586\n94\n94\n['art pop', 'pop']\n...\n0.004807\n0.005700\n0.226971\n0.703515\n0.069515\n0.995480\n0.004520\n[oh, mmmm, i, could, eat, that, girl, for, lun...\n[mmmm, could, eat, girl, lunch, dances, tongue...\n[mmmm, could, eat, girl, lunch, dance, tongue,...\n\n\n14\nEnd of Beginning\n3qhlB30KknSejmIvZZLjOD\nDECIDE\nDjo\n5p9HO3XC5P3BLxJs5Mtrhm\n2022-09-16\n159245\n93\n77\n['pov: indie', 'psychedelic pop']\n...\n0.018631\n0.004027\n0.159378\n0.691760\n0.148862\n0.964887\n0.035113\n[just, one, more, tear, to, cry, one, teardrop...\n[one, tear, cry, one, teardrop, eye, better, s...\n[one, tear, cry, one, teardrop, eye, well, sav...\n\n\n15\nwe can't be friends (wait for your love)\n46kspZSY3aKmwQe7O77fCC\neternal sunshine\nAriana Grande\n66CXWjxzNUsdJxJ2JdwvnR\n2024-03-08\n228639\n86\n91\n['pop']\n...\n0.000605\n0.000460\n0.063339\n0.507926\n0.428735\n0.996296\n0.003704\n[i, did, not, think, you, would, understand, m...\n[think, would, understand, could, ever, even, ...\n[think, would, understand, could, ever, even, ...\n\n\n16\nLose Control\n17phhZDn6oGtzMe56NuWvj\nI've Tried Everything But Therapy (Part 1)\nTeddy Swims\n33qOK5uJ8AR2xuQQAhHump\n2023-09-15\n210688\n90\n82\n[]\n...\n0.000485\n0.000120\n0.557471\n0.412347\n0.030183\n0.998184\n0.001816\n[something, is, got, a, hold, of, me, lately, ...\n[something, got, hold, lately, know, anymore, ...\n[something, get, hold, lately, know, anymore, ...\n\n\n17\nTough\n22DH8NChecsgPxDjA4pqer\nTough\nQuavo\n0VRj0yCOv2FXJNP47XQnx5\n2024-07-03\n188828\n85\n79\n['atl hip hop', 'melodic rap', 'rap', 'trap']\n...\n0.041581\n0.004940\n0.152115\n0.734467\n0.113419\n0.977612\n0.022388\n[tough, like, the, scuff, on, a, pair, of, old...\n[tough, like, scuff, pair, old, leather, boots...\n[tough, like, scuff, pair, old, leather, boot,...\n\n\n18\nAustin\n4NJqhmkGN042BrvHoMKUrJ\nAustin\nDasha\n7Ez6lTtSMjMf2YSYpukP1I\n2023-11-17\n171782\n41\n75\n[]\n...\n0.002042\n0.000548\n0.332335\n0.619888\n0.047777\n0.997655\n0.002345\n[we, had, a, plan, move, out, of, this, town, ...\n[plan, move, town, baby, west, sand, talked, l...\n[plan, move, town, baby, west, sand, talk, lat...\n\n\n19\nI Can Do It With a Broken Heart\n4q5YezDOIPcoLr8R81x9qy\nTHE TORTURED POETS DEPARTMENT\nTaylor Swift\n06HL4z0CvFAxyc27GXpf02\n2024-04-18\n218004\n87\n100\n['pop']\n...\n0.001501\n0.000734\n0.268903\n0.570628\n0.160469\n0.992031\n0.007969\n[i, can, read, your, mind, she, is, having, th...\n[read, mind, time, life, glittering, prime, li...\n[read, mind, time, life, glitter, prime, light...\n\n\n20\nHoudini\n2HYFX63wP3otVIvopRS99Z\nHoudini\nEminem\n7dGJo4pcD2V6oG8kP0tJRR\n2024-05-31\n227239\n94\n91\n['detroit hip hop', 'hip hop', 'rap']\n...\n0.059232\n0.007880\n0.143081\n0.793169\n0.063750\n0.994274\n0.005726\n[hey, them, it, is, pal, uh, i, was, listening...\n[hey, pal, uh, listening, album, good, lucky, ...\n[hey, pal, uh, listen, album, good, lucky, gue...\n\n\n21\nNasty\n6NjWCIYu1W8xa3HIvcIhd4\nNasty\nTinashe\n0NIIxcxNHmOoyBx03SfTCD\n2024-04-12\n176027\n86\n73\n['alternative r&b', 'dance pop', 'metropopolis...\n...\n0.003332\n0.002755\n0.546907\n0.416473\n0.036621\n0.997654\n0.002346\n[because, it, feels, like, heaven, when, it, h...\n[feels, like, heaven, hurts, bad, baby, put, l...\n[feel, like, heaven, hurt, bad, baby, put, lik...\n\n\n22\nBelong Together\n5uQ7de4EWjb3rkcFxyEOpu\nBelong Together\nMark Ambor\n11p2E654TTU8e0nZWBR4AL\n2024-02-16\n148317\n91\n76\n['singer-songwriter pop']\n...\n0.005112\n0.002070\n0.018785\n0.284418\n0.696797\n0.206854\n0.793146\n[i, know, sleep, is, friends, with, death, but...\n[know, sleep, friends, death, maybe, get, rest...\n[know, sleep, friend, death, maybe, get, rest,...\n\n\n23\nSlow It Down\n51eSHglvG1RJXtL3qI5trr\nFireworks & Rollerblades\nBenson Boone\n22wbnEMDvgVIAGdFeek6ET\n2024-04-05\n161831\n89\n85\n['singer-songwriter pop']\n...\n0.669380\n0.007431\n0.709808\n0.263808\n0.026384\n0.983390\n0.016610\n[i, would, never, met, you, but, i, wanted, to...\n[would, never, met, wanted, invite, party, wal...\n[would, never, meet, want, invite, party, walk...\n\n\n24\nHOT TO GO!\n4xdBrk0nFZaP54vvZj0yx7\nThe Rise and Fall of a Midwest Princess\nChappell Roan\n7GlBOeep6PqTfFi59PTUUN\n2023-09-22\n184841\n88\n86\n['indie pop', 'pov: indie']\n...\n0.001401\n0.002167\n0.105176\n0.805817\n0.089007\n0.988687\n0.011313\n[five, six, five, six, seven, eight, i, could,...\n[five, six, five, six, seven, eight, could, on...\n[five, six, five, six, seven, eight, could, on...\n\n\n25\nGIRLS\n7z3PblAN3dH1JMewiRydkZ\nGIRLS\nThe Kid LAROI\n2tIP7SsRs7vjIcLrU85W8J\n2024-06-28\n152979\n82\n81\n['australian hip hop']\n...\n0.004544\n0.001163\n0.171786\n0.707467\n0.120747\n0.994324\n0.005676\n[fall, in, love, for, no, reason, fallin, uh, ...\n[fall, love, reason, fallin, uh, turned, said,...\n[fall, love, reason, fallin, uh, turn, say, gi...\n\n\n26\ngreedy\n3rUGC1vUpkDG9CZFHMur1t\ngreedy\nTate McRae\n45dkTj5sMRSjrmBSBeiHym\n2023-09-15\n131872\n89\n82\n['pop']\n...\n0.001383\n0.000401\n0.257882\n0.650690\n0.091428\n0.970451\n0.029549\n[wood, he, said, are, you, serious, i, have, t...\n[wood, said, serious, tried, figure, next, nig...\n[wood, say, serious, tried, figure, next, nigh...\n\n\n27\nMove\n1BJJbSX6muJVF2AK7uH1x4\nMove\nAdam Port\n2loEsOijJ6XiGzWYFXMIRk\n2024-06-07\n177598\n86\n72\n['melodic house']\n...\n0.001471\n0.001813\n0.125568\n0.807287\n0.067145\n0.155766\n0.844234\n[fire, burning, style, gunning, any, i, am, fe...\n[fire, burning, style, gunning, feenin, want, ...\n[fire, burning, style, gun, feenin, want, tast...\n\n\n28\nFortnight (feat. Post Malone)\n2OzhQlSqBEmt7hmkYxfT6m\nTHE TORTURED POETS DEPARTMENT\nTaylor Swift\n06HL4z0CvFAxyc27GXpf02\n2024-04-18\n228965\n91\n100\n['pop']\n...\n0.097827\n0.012489\n0.494738\n0.437140\n0.068122\n0.984428\n0.015572\n[i, should, have, been, taken, away, but, peop...\n[taken, away, people, forgot, come, pick, alco...\n[take, away, people, forget, come, pick, alcoh...\n\n\n29\nSaturn\n1bjeWoagtHmUKputLVyDxQ\nSaturn\nSZA\n7tYKF4w9nC0nq9CsPZTHyP\n2024-02-22\n186191\n90\n89\n['pop', 'r&b', 'rap']\n...\n0.077055\n0.002667\n0.401661\n0.494084\n0.104256\n0.998026\n0.001974\n[if, there, is, another, universe, please, mak...\n[another, universe, please, make, noise, noise...\n[another, universe, please, make, noise, noise...\n\n\n30\n28\n5iJKGpnFfvbjZJeAtwXfCj\nThe Great American Bar Scene\nZach Bryan\n40ZNYROS4zLfyyBSs2PGe2\n2024-07-04\n233333\n81\n91\n['classic oklahoma country']\n...\n0.000493\n0.000980\n0.127071\n0.535515\n0.337414\n0.918328\n0.081672\n[you, took, a, train, to, the, south, side, of...\n[took, train, south, side, boson, showed, old,...\n[take, train, south, side, boson, show, old, m...\n\n\n31\nClose To You\n5MPi9e7z46wopyad10R6qx\nClose To You\nGracie Abrams\n4tuJ0bMpJh08umKkEXKUI5\n2024-06-07\n225973\n77\n82\n['alt z']\n...\n0.080101\n0.008835\n0.207858\n0.741581\n0.050560\n0.963049\n0.036952\n[close, to, you, close, to, you, i, do, not, g...\n[close, close, got, single, problem, provocati...\n[close, close, get, single, problem, provocati...\n\n\n32\nthe boy is mine\n0Lmbke3KNVFXtoH2mMSHCw\neternal sunshine\nAriana Grande\n66CXWjxzNUsdJxJ2JdwvnR\n2024-03-08\n173639\n86\n91\n['pop']\n...\n0.009534\n0.002129\n0.181925\n0.762790\n0.055285\n0.988922\n0.011078\n[how, can, it, be, you, and, me, might, be, me...\n[might, meant, unseen, want, scene, usually, u...\n[might, mean, unseen, want, scene, usually, un...\n\n\n33\nStick Season\n0mflMxspEfB0VbI1kyLiAv\nStick Season\nNoah Kahan\n2RQXRUsr4IW1f3mKyKsy4B\n2022-10-14\n182346\n90\n84\n['pov: indie']\n...\n0.104740\n0.003200\n0.516024\n0.447031\n0.036945\n0.998780\n0.001220\n[as, you, promised, me, that, i, was, more, th...\n[promised, miles, combined, must, change, hear...\n[promise, mile, combine, must, change, heart, ...\n\n\n34\nI Don't Wanna Wait\n331l3xABO0HMr1Kkyh2LZq\nI Don't Wanna Wait\nDavid Guetta\n1Cs0zKBU1kc0i8ypK3B9ai\n2024-04-05\n149667\n90\n89\n['big room', 'dance pop', 'edm', 'pop', 'pop d...\n...\n0.000750\n0.001233\n0.186699\n0.667073\n0.146227\n0.926766\n0.073234\n[let, us, make, tonight, the, weekend, i, do, ...\n[let, us, make, tonight, weekend, want, waiait...\n[let, u, make, tonight, weekend, want, waiait,...\n\n\n35\nSmeraldo Garden Marching Band (feat. Loco)\n1kPhV0KQui1phEpjnWIqUN\nSmeraldo Garden Marching Band (feat. Loco)\nJimin\n1oSPZhvZMIrWW5I41kPkkY\n2024-06-28\n182840\n91\n84\n['k-pop']\n...\n0.002519\n0.001851\n0.053019\n0.700006\n0.246975\n0.068059\n0.931941\n[say, oh, this, harmonys, just, for, you, oh, ...\n[say, harmonys, say, love, introducing, began,...\n[say, harmony, say, love, introduce, begin, tu...\n\n\n36\nStumblin' In\n0h3Xy4V4apMraB5NuM8U7Z\nStumblin' In\nCYRIL\n11kt6ggsdxvI8MhyeSMKom\n2023-11-10\n213363\n89\n79\n[]\n...\n0.327841\n0.003080\n0.325368\n0.583619\n0.091013\n0.995401\n0.004599\n[our, love, is, alive, and, so, we, begin, foo...\n[love, alive, begin, foolishly, laying, hearts...\n[love, alive, begin, foolishly, lay, heart, ta...\n\n\n37\n360\n4w2GLmK2wnioVnb5CPQeex\nBRAT\nCharli xcx\n25uiPmTg16RbhZWAqwLBy5\n2024-06-07\n133805\n84\n85\n['art pop', 'candy pop', 'metropopolis', 'pop'...\n...\n0.012352\n0.004491\n0.165593\n0.730096\n0.104311\n0.991431\n0.008569\n[i, went, my, own, way, and, i, made, it, i, a...\n[went, way, made, favorite, reference, baby, c...\n[go, way, make, favorite, reference, baby, cal...\n\n\n38\nRockstar\n6vvPecFTmWxDfEJ6cYT1wa\nRockstar\nLISA\n5L1lO4eRHmJ7a0Q6csE5cT\n2024-06-27\n138213\n90\n79\n['k-pop']\n...\n0.036838\n0.012582\n0.055340\n0.774254\n0.170406\n0.981867\n0.018133\n[gold, teeth, sitting, on, the, dash, she, a, ...\n[gold, teeth, sitting, dash, rockstar, make, f...\n[gold, teeth, sit, dash, rockstar, make, favor...\n\n\n39\nOne Of The Girls (with JENNIE, Lily Rose Depp)\n7CyPwkp0oE8Ro9Dd5CUDjW\nThe Idol Episode 4 (Music from the HBO Origina...\nThe Weeknd\n1Xyo4u8uXC1ZmMpatF05PJ\n2023-06-23\n244684\n91\n93\n['canadian contemporary r&b', 'canadian pop', ...\n...\n0.018034\n0.003468\n0.178038\n0.707149\n0.114813\n0.885132\n0.114868\n[lock, me, up, and, throw, away, the, key, he,...\n[lock, throw, away, key, knows, get, best, for...\n[lock, throw, away, key, know, get, best, forc...\n\n\n40\nScared To Start\n3Pbp7cUCx4d3OAkZSCoNvn\nScared To Start\nMichael Marcagi\n4j96cMcT8GRi11qbvo1cLQ\n2024-01-12\n159636\n88\n73\n[]\n...\n0.993651\n0.000680\n0.467322\n0.498693\n0.033985\n0.993110\n0.006890\n[she, is, wearing, an, old, dress, walking, it...\n[wearing, old, dress, walking, waiting, someon...\n[wear, old, dress, walk, wait, someone, turn, ...\n\n\n41\nLies Lies Lies\n7Fzl7QaTu47WyP9R5S5mh5\nLies Lies Lies\nMorgan Wallen\n4oUHIQIBe0LHzYfvXNW4QM\n2024-07-05\n198068\n80\n90\n['contemporary country']\n...\n0.005516\n0.000481\n0.621788\n0.354477\n0.023735\n0.990984\n0.009016\n[i, do, not, come, down, with, the, sun, i, wi...\n[come, sun, hate, morning, comes, thoughts, bo...\n[come, sun, hate, morning, come, thought, body...\n\n\n42\nfeelslikeimfallinginlove\n1YsU8rW2u8z4F0pwOBQ4Ea\nfeelslikeimfallinginlove\nColdplay\n4gzpq5DPGxSnKTe4SA8HAU\n2024-06-21\n237803\n83\n88\n['permanent wave', 'pop']\n...\n0.001050\n0.000178\n0.352217\n0.564125\n0.083659\n0.954148\n0.045852\n[i, know, that, this, could, hurt, me, bad, i,...\n[know, could, hurt, bad, know, could, feel, li...\n[know, could, hurt, bad, know, could, feel, li...\n\n\n43\nParking Lot\n4IFd7EVCyJsUHesBMXI8ju\nParking Lot\nMustard\n0YinUQ50QDB7ZxSCLyQ40k\n2024-06-21\n172794\n83\n73\n['cali rap', 'pop rap', 'rap', 'southern hip h...\n...\n0.091244\n0.010612\n0.097719\n0.778541\n0.123740\n0.991387\n0.008613\n[away, away, away, away, away, away, away, awa...\n[away, away, away, away, away, away, away, awa...\n[away, away, away, away, away, away, away, awa...\n\n\n44\nGata Only\n6XjDF6nds4DE2BBbagZol6\nGata Only\nFloyyMenor\n7CvTknweLr9feJtRGrpDBy\n2024-02-02\n222000\n96\n82\n['reggaeton chileno']\n...\n0.884537\n0.003583\n0.210103\n0.690181\n0.099717\n0.996415\n0.003585\n[hey, mommy, i, feel, you, far, away, tell, me...\n[hey, mommy, feel, far, away, tell, want, goin...\n[hey, mommy, feel, far, away, tell, want, go, ...\n\n\n45\nBAND4BAND (feat. Lil Baby)\n7iabz12vAuVQYyekFIWJxD\nBAND4BAND (feat. Lil Baby)\nCentral Cee\n5H4yInM5zmHqpKIoMNAx4r\n2024-05-23\n140733\n91\n82\n['melodic drill', 'r&drill']\n...\n0.031337\n0.003643\n0.158056\n0.726879\n0.115065\n0.995000\n0.005000\n[i, am, not, in, the, mood, because, my, fligh...\n[mood, flight, delayed, jumped, private, jet, ...\n[mood, flight, delay, jump, private, jet, ask,...\n\n\n46\nSanta\n5bi0gh89wRuH2OgjdAKFsb\nSanta\nRvssian\n1fctva4kpRbg2k3v7kwRuS\n2024-04-04\n193038\n88\n76\n['reggaeton', 'reggaeton flow', 'trap latino',...\n...\n0.221692\n0.006951\n0.261035\n0.679751\n0.059214\n0.986848\n0.013152\n[they, rvssian, i, can, not, deny, this, desir...\n[rvssian, deny, desire, stop, looking, lips, r...\n[rvssian, deny, desire, stop, look, lip, rejec...\n\n\n47\nMagnetic\n1aKvZDoLGkNMxoRYgkckZG\nSUPER REAL ME\nILLIT\n36cgvBn0aadzOijnjjwqMN\n2024-03-25\n160688\n89\n74\n['5th gen k-pop']\n...\n0.069957\n0.007273\n0.092965\n0.713226\n0.193809\n0.986112\n0.013888\n[baby, i, am, just, trying, to, play, it, cool...\n[baby, trying, play, cool, hide, want, wait, m...\n[baby, try, play, cool, hide, want, wait, minu...\n\n\n48\nWater\n5aIVCx5tnk0ntmdiinnYvw\nWater\nTyla\n3SozjO3Lat463tQICI9LcE\n2023-07-28\n200255\n86\n77\n[]\n...\n0.006878\n0.002168\n0.210546\n0.642083\n0.147372\n0.992614\n0.007386\n[make, me, sweat, make, me, hotter, make, me, ...\n[make, sweat, make, hotter, make, lose, breath...\n[make, sweat, make, hotter, make, lose, breath...\n\n\n49\nIllusion\n59xD5osEFsaNt5PXfIKUnX\nIllusion\nDua Lipa\n6M2wZ9GZgrQXHCFfjv46we\n2024-04-11\n188143\n79\n88\n['dance pop', 'pop', 'uk pop']\n...\n0.292987\n0.295016\n0.178378\n0.761315\n0.060307\n0.980528\n0.019472\n[i, been, known, to, miss, a, red, flag, i, be...\n[known, miss, red, flag, known, put, lover, pe...\n[know, miss, red, flag, know, put, lover, pede...\n\n\n\n\n50 rows × 39 columns",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "02_genre_classification/01_classification_model.html",
    "href": "02_genre_classification/01_classification_model.html",
    "title": "Genre Classification Model",
    "section": "",
    "text": "Objective. Construct a classification model that can accurately predict the genre of a song using a dataset containing Spotify track information, including artist details and genres. The model will utilize the audio features and potentially the lyrics of each track to make its predictions. Additionally, it will be trained using the artist genre list as well as a separate dataset of tracks that have been labeled with their respective genres.\nConstructing a classification model to predict the genre of a song involves several steps, including data preprocessing, feature engineering, model selection, training, and evaluation. Here’s a step-by-step guide to achieve this:\n\ngenres_v2['genre'].value_counts()\n\npop         142\nacoustic    139\nemo         139\nchill       139\ngrunge      134\npunk        134\nromance     133\nrock        132\nsad         132\nhappy       132\npiano       131\nhip-hop     130\nindie       129\ndance       127\ntechno       95\nr-n-b        91\nedm          84\nName: genre, dtype: int64\n\n\n\nStep 1: Data Collection\nGather the necessary datasets: - Spotify API: Use the Spotify API to collect track information, including audio features (e.g., danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo). - Artist Genre Data: Gather genres associated with each artist from Spotify’s API. - Lyrics Data: Includes the lyrics of the tracks (optional but can enhance the model’s performance). - Genre Labels: Obtain a labeled dataset of tracks with their respective genres for training.\nWe want to try and predict a song’s genre based off of these audio features. Spotify provides a “genre seed:” an array of genres associated with the song used for the recommendation function of the API. We use the API to search for the top 1000 songs in a given genre, pull the audio features for each song, and add on the genre label.\n\n\n\n\n\n\n\n\n\n\npopularity\nacousticness\ndanceability\nenergy\ninstrumentalness\nliveness\nloudness\nspeechiness\ntempo\nvalence\nkey\nmode\ntime_signature\n\n\n\n\ncount\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n2143.000000\n\n\nmean\n28.085394\n0.229999\n0.559915\n0.654700\n0.114476\n0.188180\n-7.523677\n0.078464\n122.833333\n0.438788\n5.211386\n0.645824\n3.929071\n\n\nstd\n27.611174\n0.312395\n0.165951\n0.245871\n0.265948\n0.151159\n4.443536\n0.078789\n28.301679\n0.231271\n3.584855\n0.478375\n0.377482\n\n\nmin\n0.000000\n0.000001\n0.062100\n0.001500\n0.000000\n0.021500\n-41.446000\n0.022600\n42.646000\n0.027500\n0.000000\n0.000000\n1.000000\n\n\n25%\n0.000000\n0.005250\n0.446000\n0.488500\n0.000000\n0.095900\n-8.931000\n0.035500\n100.304500\n0.255000\n2.000000\n0.000000\n4.000000\n\n\n50%\n26.000000\n0.058200\n0.559000\n0.710000\n0.000044\n0.126000\n-6.340000\n0.048200\n123.279000\n0.415000\n5.000000\n1.000000\n4.000000\n\n\n75%\n53.000000\n0.362000\n0.678500\n0.856000\n0.012050\n0.234000\n-4.699500\n0.083600\n139.987000\n0.610000\n8.000000\n1.000000\n4.000000\n\n\nmax\n85.000000\n0.996000\n0.969000\n0.999000\n0.978000\n0.988000\n-1.264000\n0.578000\n214.008000\n0.980000\n11.000000\n1.000000\n5.000000\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Data Preprocessing\nClean and preprocess the data to prepare it for model training. - Handle Missing Values: Remove or impute missing data. - Normalize/Standardize Features: Normalize or standardize the audio features to ensure they are on a similar scale. - Text Preprocessing for Lyrics: Tokenize, remove stopwords, and potentially use techniques like TF-IDF or word embeddings for the lyrics.\n\n# Normalize audio features\nfrom sklearn.preprocessing import StandardScaler\n\n# Define audio features\naudio_features = ['danceability', 'energy', 'key', 'loudness', 'speechiness', 'acousticness',\n                  'instrumentalness', 'liveness', 'valence', 'tempo']\n\n# Fit and transform audio features\nscaler = StandardScaler()\ndf[audio_features] = scaler.fit_transform(df[audio_features])\n\n\n\n\nStep 3. Feature Engineering\nCreate features from the available data. - Audio Features: Use the provided audio features. - Artist Genre Encoding: Encode categorical features (i.e. genres) using one-hot encoding or other suitable methods. - Lyrics Features: Convert lyrics into numerical features using techniques like TF-IDF, Word2Vec, or BERT embeddings. - Extract additional features from lyrics (e.g., sentiment analysis, topic modeling).\n\nLabel Encoder\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()  # Encode the target variable\ndf['genre_encoded'] = le.fit_transform(df['genre'])\n\nCombine and arrange the data to create a final dataset for training the model.\n\nX = df[['danceability', 'energy', 'key', 'loudness', 'speechiness',\n        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\ny = df[['genre_encoded']]\n\n\n\n\n\nStep 4: Model Selection and Training\nChoose an appropriate classification algorithm and train the model. - Algorithms: Consider using algorithms like Random Forest, Gradient Boosting, Support Vector Machine (SVM), or Neural Networks. - Cross-Validation: Use cross-validation to tune hyperparameters and avoid overfitting.\n\nModel Training\nThe following code divides a dataset into training and testing subsets. It divides the input variables and target variables into 80% training and 20% testing groups at random. The descriptive statistics of the training data are then outputted to aid in data exploration and the identification of possible problems.\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # test_size=0.2\n\n\n\nModel Fitting\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nfrom prettytable import PrettyTable\n\n\n# Define models\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=0.5, random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=5, random_state=42),\n    \"SVM\": SVC(probability=True, random_state=42),\n    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n    \"Decision Tree\": DecisionTreeClassifier(max_depth=7, min_samples_split=5, random_state=42),\n    \"Gradient Boost\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, random_state=42),\n    \"XGB\": XGBClassifier(n_estimators=300, random_state=42)\n}\n\n\n\n\n\nStep 6: Model Evaluation\nEvaluate the model’s performance using appropriate metrics. - Metrics: Use accuracy, precision, recall, F1-score, and confusion matrix to assess the model. - Validation Set: Use a separate validation set to test the model’s generalization ability.\nWe can evaluate the performance of different models using multiple criteria: Accuracy, ROC-AUC, Precision, Recall, and F1-Score. Based on the provided metrics, let’s analyze the performance of each model to determine which one is the best:\n\n# Initialize an empty list to store the results\nresults = []\n\n# Train models and evaluate\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n\n    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n\n    results.append({\n        \"Model\": name, \n        \"Accuracy\": accuracy_score(y_test, y_pred), \n        \"ROC-AUC\": roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else None,\n        \"Precision\": report['weighted avg']['precision'], \n        \"Recall\": report['weighted avg']['recall'], \n        \"F1-Score\": report['weighted avg']['f1-score']\n    })\n\n\n\n\n\n\n\n\n\n \nModel\nAccuracy\nROC-AUC\nPrecision\nRecall\nF1-Score\n\n\n\n\n0\nLogistic Regression\n0.292910\n0.823484\n0.322340\n0.292910\n0.275275\n\n\n1\nRandom Forest\n0.266791\n0.826900\n0.257971\n0.266791\n0.237800\n\n\n2\nSVM\n0.270522\n0.816350\n0.275629\n0.270522\n0.252128\n\n\n3\nNeural Network\n0.268657\n0.815905\n0.270748\n0.268657\n0.258513\n\n\n4\nKNN\n0.203358\n0.662278\n0.201823\n0.203358\n0.191504\n\n\n5\nDecision Tree\n0.238806\n0.729930\n0.262212\n0.238806\n0.223554\n\n\n6\nGradient Boost\n0.270522\n0.808805\n0.269965\n0.270522\n0.263241\n\n\n7\nXGB\n0.248134\n0.778676\n0.249968\n0.248134\n0.241814\n\n\n\n\n\n\n\nConclusion\nConsidering all metrics, Random Forest appears to be the best model overall due to its high performance across multiple metrics (accuracy and ROC-AUC), while the Neural Network also performs well with the highest precision and F1-Score.\nThese results suggest that the Random Forest, Neural Network, and SVM models are the most effective for this specific task of predicting the genre of a song using the given dataset.\n\n\n\n\n\nStep 7: Model Deployment\nDeploy the model for practical use. - Save the Model: Save the trained model using libraries like joblib or pickle. - API Creation: Create an API using Flask or FastAPI to make predictions on new data.\n\nimport joblib\n\n# Train the Random Forest model\nrandom_forest_model = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=5, random_state=42)\nrandom_forest_model.fit(X_train, y_train)\n\n# Save scaler + model for future use\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(random_forest_model, 'random_forest_model.pkl')\n\n['random_forest_model.pkl']\n\n\n\n# Evaluate the model\ny_pred = random_forest_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\nAccuracy: 0.2667910447761194\n\n\n\nApplying Model to New Data\n\n# Load the trained models + scaler\nrandom_forest_model = joblib.load('random_forest_model.pkl')\nscaler = joblib.load('scaler.pkl')\n\n\n# Load new data\ndf_new = pd.read_csv(\"../assets/data/all_tracks+lyrics.csv\")\n\n# Extract relevant columns\nnew_data = df_new[['name', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n                   'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n\n# Preprocess new data\nX_new_data = new_data.drop(columns=['name'])\nX_new_data_scaled = scaler.transform(X_new_data)\n\n\n# Make predictions\npredictions = random_forest_model.predict(X_new_data_scaled)\nprobabilities = random_forest_model.predict_proba(X_new_data_scaled)\n\n# Decode the predicted genre labels\npredictions_label = le.inverse_transform(predictions)\n\n# Display predictions\nnew_data['Predicted Genre'] = predictions\nnew_data['Predicted Genre Label'] = predictions_label\nnew_data['Prediction Probabilities'] = probabilities.tolist()\n\nnew_data[['name', 'Predicted Genre Label', 'Predicted Genre', 'Prediction Probabilities']]\n\n\n\n\n\n\n\n\n\nname\nPredicted Genre Label\nPredicted Genre\nPrediction Probabilities\n\n\n\n\n0\nPlease Please Please\npop\n10\n[0.04088154652446443, 0.07714395919805248, 0.0...\n\n\n1\nSi Antes Te Hubiera Conocido\npop\n10\n[0.052278933050807844, 0.06228149646432559, 0....\n\n\n2\nBIRDS OF A FEATHER\ndance\n2\n[0.07264102912485536, 0.10432647001182196, 0.1...\n\n\n3\nGood Luck, Babe!\npop\n10\n[0.05870991975676431, 0.09131179743471457, 0.0...\n\n\n4\nA Bar Song (Tipsy)\npop\n10\n[0.04773552198684028, 0.0836338792955852, 0.04...\n\n\n5\nNot Like Us\nhip-hop\n7\n[0.02365012599849557, 0.07161269506638383, 0.0...\n\n\n6\nMILLION DOLLAR BABY\npop\n10\n[0.02922418578908816, 0.0647413931106139, 0.08...\n\n\n7\nToo Sweet\npop\n10\n[0.025137350612849513, 0.07401057278171215, 0....\n\n\n8\nBeautiful Things\nromance\n14\n[0.05636255764656002, 0.06888807365798695, 0.0...\n\n\n9\nI Had Some Help (Feat. Morgan Wallen)\nhappy\n6\n[0.0324812151873648, 0.07718756832982102, 0.09...\n\n\n10\nEspresso\npop\n10\n[0.03976771088890484, 0.11091839764030585, 0.0...\n\n\n11\ni like the way you kiss me\nrock\n13\n[0.00560173930301027, 0.027934558669221385, 0....\n\n\n12\nStargazing\nromance\n14\n[0.07844059571018996, 0.08715430776260266, 0.0...\n\n\n13\nLUNCH\ndance\n2\n[0.06268786025919988, 0.04074153271739373, 0.2...\n\n\n14\nEnd of Beginning\ndance\n2\n[0.058459964608319995, 0.045299973823992, 0.14...\n\n\n15\nwe can't be friends (wait for your love)\npop\n10\n[0.04767297734830211, 0.09013230830759586, 0.0...\n\n\n16\nLose Control\nromance\n14\n[0.06999320818385321, 0.09762855667926634, 0.0...\n\n\n17\nTough\nacoustic\n0\n[0.1487665952511997, 0.07956401979979427, 0.02...\n\n\n18\nAustin\npop\n10\n[0.05794414166297137, 0.07773720145272671, 0.0...\n\n\n19\nI Can Do It With a Broken Heart\npop\n10\n[0.04152820229550991, 0.07795210201071162, 0.0...\n\n\n20\nHoudini\npop\n10\n[0.012428955551854977, 0.04178841837693284, 0....\n\n\n21\nNasty\npop\n10\n[0.07229835155549594, 0.07798138478900962, 0.0...\n\n\n22\nBelong Together\npop\n10\n[0.1184642865957953, 0.08894661601186675, 0.04...\n\n\n23\nSlow It Down\nromance\n14\n[0.04562594460281343, 0.06860379702332979, 0.0...\n\n\n24\nHOT TO GO!\npop\n10\n[0.018093243817939027, 0.07192985122486334, 0....\n\n\n25\nGIRLS\npop\n10\n[0.030047792403698946, 0.07162699583368382, 0....\n\n\n26\ngreedy\npop\n10\n[0.0391825562304293, 0.07982381429220817, 0.04...\n\n\n27\nMove\ndance\n2\n[0.03153192004354079, 0.0632106471284883, 0.27...\n\n\n28\nFortnight (feat. Post Malone)\nacoustic\n0\n[0.2133077064313661, 0.10533632362310526, 0.00...\n\n\n29\nSaturn\nsad\n15\n[0.15633979786968363, 0.09415369169525718, 0.0...\n\n\n30\n28\nchill\n1\n[0.08481086165547902, 0.14493631982323849, 0.0...\n\n\n31\nClose To You\npop\n10\n[0.043913102280624665, 0.07931487946844533, 0....\n\n\n32\nthe boy is mine\npop\n10\n[0.03326174503752976, 0.07819873548158905, 0.0...\n\n\n33\nStick Season\nacoustic\n0\n[0.15164660763833773, 0.08639492608005701, 0.0...\n\n\n34\nI Don't Wanna Wait\npop\n10\n[0.04034787361025403, 0.07919812766986792, 0.0...\n\n\n35\nSmeraldo Garden Marching Band (feat. Loco)\npop\n10\n[0.012025901882804802, 0.0892535139898251, 0.0...\n\n\n36\nStumblin' In\ndance\n2\n[0.03182662544837536, 0.06430270117639993, 0.1...\n\n\n37\n360\ndance\n2\n[0.08284826354380695, 0.06311558351697714, 0.2...\n\n\n38\nRockstar\npop\n10\n[0.028486403608907106, 0.06298695375092218, 0....\n\n\n39\nOne Of The Girls (with JENNIE, Lily Rose Depp)\nromance\n14\n[0.0467947393194539, 0.06589514531102753, 0.03...\n\n\n40\nScared To Start\nacoustic\n0\n[0.1788457069830126, 0.10889137568133479, 0.01...\n\n\n41\nLies Lies Lies\nromance\n14\n[0.06906881049759486, 0.12520424564543942, 0.0...\n\n\n42\nfeelslikeimfallinginlove\ndance\n2\n[0.06058770720420721, 0.10143051335809605, 0.1...\n\n\n43\nParking Lot\npop\n10\n[0.04112327314489984, 0.08773701130340866, 0.0...\n\n\n44\nGata Only\npop\n10\n[0.08002179081376724, 0.080812180724709, 0.048...\n\n\n45\nBAND4BAND (feat. Lil Baby)\nhip-hop\n7\n[0.009146801699282305, 0.04043458967408511, 0....\n\n\n46\nSanta\npop\n10\n[0.02718144861517665, 0.08773498147207358, 0.0...\n\n\n47\nMagnetic\npop\n10\n[0.030559852949859363, 0.061780658803238436, 0...\n\n\n48\nWater\npop\n10\n[0.025002878313200597, 0.06980209749484347, 0....\n\n\n49\nIllusion\npop\n10\n[0.022670167757488244, 0.06973317734184772, 0....\n\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# import track_data\ngenres_v2 = pd.read_csv(\"../assets/data/genre_seeds.csv\")\n\nclient_id = \"bd1c5f1d16b94210bc1776e172cbd264\"\nclient_secret = \"b152588a487b4f6e9429bdd1bfd92fb3\"\nsp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id, client_secret))\n\n\ndef track_features(id, artist_id, note):\n    meta = sp.track(id)\n    audio_features = sp.audio_features(id)\n    artist_info = sp.artist(artist_id)\n\n    if audio_features[0] is None:\n        return None\n\n    name = meta['name']\n    track_id = meta['id']\n    album = meta['album']['name']\n    artist = meta['album']['artists'][0]['name']\n    artist_id = meta['album']['artists'][0]['id']\n    release_date = meta['album']['release_date']\n    length = meta['duration_ms']\n    popularity = meta['popularity']\n\n    artist_pop = artist_info[\"popularity\"]\n    artist_genres = artist_info[\"genres\"]\n    artist_followers = artist_info[\"followers\"]['total']\n\n    acousticness = audio_features[0]['acousticness']\n    danceability = audio_features[0]['danceability']\n    energy = audio_features[0]['energy']\n    instrumentalness = audio_features[0]['instrumentalness']\n    liveness = audio_features[0]['liveness']\n    loudness = audio_features[0]['loudness']\n    speechiness = audio_features[0]['speechiness']\n    tempo = audio_features[0]['tempo']\n    valence = audio_features[0]['valence']\n    key = audio_features[0]['key']\n    mode = audio_features[0]['mode']\n    time_signature = audio_features[0]['time_signature']\n\n    return [name, track_id, album, artist, artist_id, release_date, length, popularity,\n            artist_pop, artist_genres, artist_followers, acousticness, danceability,\n            energy, instrumentalness, liveness, loudness, speechiness,\n            tempo, valence, key, mode, time_signature, note]\n\n\n\n\n# sp.recommendation_genre_seeds() \"trip-hop\", \"trance\"\ngenre_seeds = [\"acoustic\", \"chill\", \"dance\", \"edm\", \"emo\", \"grunge\", \"happy\", \"hip-hop\", \"indie\",\n               \"piano\", \"pop\", \"punk\", \"rock\", \"romance\", \"sad\", \"techno\", \"r-n-b\"]\n\nall_genre_seed_tracks = []\n\nfor genre in genre_seeds:\n    genre_rec = sp.recommendations(seed_genres=[genre])['tracks']\n\n    for song in genre_rec:\n        song_id = song['id']\n        song_artist_id = song['artists'][0]['id']\n        song_audio = track_features(\n            id=song_id, artist_id=song_artist_id, note=genre)\n        all_genre_seed_tracks.append(song_audio)\n\n\ndf = pd.DataFrame(all_genre_seed_tracks,\n                  columns=['name', 'track_id', 'album', 'artist', 'artist_id', 'release_date', 'length', 'popularity',\n                           'artist_pop', 'artist_genres', 'artist_followers', 'acousticness', 'danceability',\n                           'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness',\n                           'tempo', 'valence', 'key', 'mode', 'time_signature', 'genre'])\n\n\n\n\ndf_add = df.append(genres_v2, ignore_index=True)\ndf_add = df_add.drop_duplicates(subset=['track_id', 'genre'])\n#df_add = df_add.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n\ndf_add.to_csv(\"../assets/data/genre_seeds.csv\", index=None)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Genre Classification Model</span>"
    ]
  }
]